{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import re\n",
    "import glob\n",
    "import errno\n",
    "import pickle\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regex pattern for \"word\" recognition\n",
    "rgx_pos = re.compile(\"([\\w][\\w']*\\w|[!]+|[?]+)\")\n",
    "rgx_neg = re.compile(\"([\\w][\\w']*\\w|[!]+|[?]+)\")\n",
    "\n",
    "rgx_not = re.compile(\"(not [\\w][\\w']*)\")\n",
    "rgx_good = re.compile(\"(good [\\w][\\w']*)\")\n",
    "rgx_best = re.compile(\"(best [\\w][\\w']*)\")\n",
    "rgx_bad = re.compile(\"(bad [\\w][\\w']*)\")\n",
    "rgx_like = re.compile(\"(like [\\w][\\w']*)\")\n",
    "rgx_better = re.compile(\"(better [\\w][\\w']*)\")\n",
    "rgx_very = re.compile(\"(very [\\w][\\w']*)\")\n",
    "rgx_nice = re.compile(\"(nice [\\w][\\w']*)\")\n",
    "\n",
    "rgx_not_n = re.compile(\"(not [\\w][\\w']*)\")\n",
    "rgx_good_n = re.compile(\"(good [\\w][\\w']*)\")\n",
    "rgx_best_n = re.compile(\"(best [\\w][\\w']*)\")\n",
    "rgx_bad_n = re.compile(\"(bad [\\w][\\w']*)\")\n",
    "rgx_like_n = re.compile(\"(like [\\w][\\w']*)\")\n",
    "rgx_better_n = re.compile(\"(better [\\w][\\w']*)\")\n",
    "rgx_very_n = re.compile(\"(very [\\w][\\w']*)\")\n",
    "rgx_nice_n = re.compile(\"(nice [\\w][\\w']*)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pos = []\n",
    "not_words = []\n",
    "good_words = []\n",
    "best_words = []\n",
    "bad_words = []\n",
    "like_words = []\n",
    "better_words = []\n",
    "very_words = []\n",
    "nice_words = []\n",
    "\n",
    "\n",
    "path = '/Users/felixrolf/PycharmProjects/my_voice_predictor/data/movies/pos_train/'\n",
    "all_files = glob.glob(path + '*.txt')\n",
    "#translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "for filename in all_files:\n",
    "    file = open(filename, 'r')\n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        words_pos += rgx_pos.findall(line)\n",
    "        not_words += rgx_not.findall(line)\n",
    "        good_words += rgx_good.findall(line)\n",
    "        best_words += rgx_best.findall(line)\n",
    "        bad_words += rgx_bad.findall(line)\n",
    "        like_words += rgx_like.findall(line)\n",
    "        better_words += rgx_better.findall(line)\n",
    "        very_words += rgx_very.findall(line)\n",
    "        nice_words += rgx_nice.findall(line)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_neg = []\n",
    "not_words_n = []\n",
    "good_words_n = []\n",
    "best_words_n = []\n",
    "bad_words_n = []\n",
    "like_words_n = []\n",
    "better_words_n = []\n",
    "very_words_n = []\n",
    "nice_words_n = []\n",
    "\n",
    "\n",
    "path = '/Users/felixrolf/PycharmProjects/my_voice_predictor/data/movies/neg_train/'\n",
    "all_files = glob.glob(path + '*.txt')\n",
    "\n",
    "for filename in all_files:\n",
    "    file = open(filename, 'r')\n",
    "    for line in file:\n",
    "        # clean up line (use regex)\n",
    "        line = line.lower()\n",
    "        words_neg += rgx_neg.findall(line)\n",
    "        not_words_n += rgx_not_n.findall(line)\n",
    "        good_words_n += rgx_good_n.findall(line)\n",
    "        best_words_n += rgx_best_n.findall(line)\n",
    "        bad_words_n += rgx_bad_n.findall(line)\n",
    "        like_words_n += rgx_like_n.findall(line)\n",
    "        better_words_n += rgx_better_n.findall(line)\n",
    "        very_words_n += rgx_very_n.findall(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pos = pd.DataFrame(words_pos)\n",
    "words_neg = pd.DataFrame(words_neg)\n",
    "\n",
    "not_words = pd.DataFrame(not_words)\n",
    "good_words = pd.DataFrame(good_words)\n",
    "best_words = pd.DataFrame(best_words)\n",
    "bad_words = pd.DataFrame(bad_words)\n",
    "like_words = pd.DataFrame(like_words)\n",
    "better_words = pd.DataFrame(better_words)\n",
    "very_words = pd.DataFrame(very_words)\n",
    "nice_words = pd.DataFrame(nice_words)\n",
    "\n",
    "\n",
    "not_words_n = pd.DataFrame(not_words_n)\n",
    "good_words_n = pd.DataFrame(good_words_n)\n",
    "best_words_n = pd.DataFrame(best_words_n)\n",
    "bad_words_n = pd.DataFrame(bad_words_n)\n",
    "like_words_n = pd.DataFrame(like_words_n)\n",
    "better_words_n = pd.DataFrame(better_words_n)\n",
    "very_words_n = pd.DataFrame(very_words_n)\n",
    "nice_words_n = pd.DataFrame(nice_words_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pos['count'] = 1\n",
    "words_neg['count'] = 1\n",
    "\n",
    "not_words['count'] = 1\n",
    "good_words['count'] = 1\n",
    "best_words['count'] = 1\n",
    "bad_words['count'] = 1\n",
    "like_words['count'] = 1\n",
    "better_words['count'] = 1\n",
    "very_words['count'] = 1\n",
    "nice_words['count'] = 1\n",
    "\n",
    "not_words_n['count'] = 1\n",
    "good_words_n['count'] = 1\n",
    "best_words_n['count'] = 1\n",
    "bad_words_n['count'] = 1\n",
    "like_words_n['count'] = 1\n",
    "better_words_n['count'] = 1\n",
    "very_words_n['count'] = 1\n",
    "nice_words_n['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pos = words_pos.rename(index=int, columns={0:\"text\"})\n",
    "words_neg = words_neg.rename(index=int, columns={0:\"text\"})\n",
    "\n",
    "not_words = not_words.rename(index=int, columns={0:\"text\"})\n",
    "good_words = good_words.rename(index=int, columns={0:\"text\"})\n",
    "best_words = best_words.rename(index=int, columns={0:\"text\"})\n",
    "bad_words = bad_words.rename(index=int, columns={0:\"text\"})\n",
    "like_words = like_words.rename(index=int, columns={0:\"text\"})\n",
    "better_words = better_words.rename(index=int, columns={0:\"text\"})\n",
    "very_words = very_words.rename(index=int, columns={0:\"text\"})\n",
    "nice_words = nice_words.rename(index=int, columns={0:\"text\"})\n",
    "\n",
    "not_words_n = not_words_n.rename(index=int, columns={0:\"text\"})\n",
    "good_words_n = good_words_n.rename(index=int, columns={0:\"text\"})\n",
    "best_words_n = best_words_n.rename(index=int, columns={0:\"text\"})\n",
    "bad_words_n = bad_words_n.rename(index=int, columns={0:\"text\"})\n",
    "like_words_n = like_words_n.rename(index=int, columns={0:\"text\"})\n",
    "better_words_n = better_words_n.rename(index=int, columns={0:\"text\"})\n",
    "very_words_n = very_words_n.rename(index=int, columns={0:\"text\"})\n",
    "nice_words_n = nice_words_n.rename(index=int, columns={0:\"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_pos = words_pos.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_neg = words_neg.groupby('text').count().sort_values('count', ascending=False)\n",
    "\n",
    "sorting_not  = not_words.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_good  = good_words.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_best  = best_words.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_bad  = bad_words.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_like  = like_words.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_better  = better_words.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_very  = very_words.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_nice  = nice_words.groupby('text').count().sort_values('count', ascending=False)\n",
    "\n",
    "sorting_not_n  = not_words_n.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_good_n  = good_words_n.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_best_n  = best_words_n.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_bad_n  = bad_words_n.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_like_n  = like_words_n.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_better_n  = better_words_n.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_very_n  = very_words_n.groupby('text').count().sort_values('count', ascending=False)\n",
    "sorting_nice_n  = nice_words_n.groupby('text').count().sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = sorting_pos.merge(sorting_neg, left_on='text', right_on='text')\n",
    "\n",
    "sorting_not = sorting_not.merge(sorting_not_n, left_on='text', right_on='text')\n",
    "sorting_good = sorting_good.merge(sorting_good_n, left_on='text', right_on='text')\n",
    "sorting_best = sorting_best.merge(sorting_best_n, left_on='text', right_on='text')\n",
    "sorting_bad = sorting_bad.merge(sorting_bad_n, left_on='text', right_on='text')\n",
    "sorting_like = sorting_like.merge(sorting_like_n, left_on='text', right_on='text')\n",
    "sorting_better = sorting_better.merge(sorting_better_n, left_on='text', right_on='text')\n",
    "sorting_very = sorting_very.merge(sorting_very_n, left_on='text', right_on='text')\n",
    "sorting_nice = sorting_nice.merge(sorting_nice_n, left_on='text', right_on='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting['count_z'] = sorting['count_x']+sorting['count_y']\n",
    "\n",
    "sorting_not['count_z'] = sorting_not['count_x']+sorting_not['count_y']\n",
    "sorting_good['count_z'] = sorting_good['count_x']+sorting_good['count_y']\n",
    "sorting_best['count_z'] = sorting_best['count_x']+sorting_best['count_y']\n",
    "sorting_bad['count_z'] = sorting_bad['count_x']+sorting_bad['count_y']\n",
    "sorting_like['count_z'] = sorting_like['count_x']+sorting_like['count_y']\n",
    "sorting_better['count_z'] = sorting_better['count_x']+sorting_better['count_y']\n",
    "sorting_very['count_z'] = sorting_very['count_x']+sorting_very['count_y']\n",
    "sorting_nice['count_z'] = sorting_nice['count_x']+sorting_nice['count_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight word tuples\n",
    "sorting.eval('weight = (count_x - count_y)**2 / (count_x + count_y)', inplace=True)\n",
    "\n",
    "sorting_not.eval('weight = (count_x - count_y)**2 / (count_x + count_y)', inplace=True)\n",
    "sorting_good.eval('weight = (count_x - count_y)**2 / (count_x + count_y)', inplace=True)\n",
    "sorting_best.eval('weight = (count_x - count_y)**2 / (count_x + count_y)', inplace=True)\n",
    "sorting_bad.eval('weight = (count_x - count_y)**2 / (count_x + count_y)', inplace=True)\n",
    "sorting_like.eval('weight = (count_x - count_y)**2 / (count_x + count_y)', inplace=True)\n",
    "sorting_better.eval('weight = (count_x - count_y)**2 / (count_x + count_y)', inplace=True)\n",
    "sorting_very.eval('weight = (count_x - count_y)**2 / (count_x + count_y)', inplace=True)\n",
    "sorting_nice.eval('weight = (count_x - count_y)**2 / (count_x + count_y)', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = sorting.groupby('text').sum().sort_values('weight', ascending=False)\n",
    "\n",
    "sorting_not = sorting_not.groupby('text').sum().sort_values('weight', ascending=False)\n",
    "sorting_good = sorting_good.groupby('text').sum().sort_values('weight', ascending=False)\n",
    "sorting_best = sorting_best.groupby('text').sum().sort_values('weight', ascending=False)\n",
    "sorting_bad = sorting_bad.groupby('text').sum().sort_values('weight', ascending=False)\n",
    "sorting_like = sorting_like.groupby('text').sum().sort_values('weight', ascending=False)\n",
    "sorting_better = sorting_better.groupby('text').sum().sort_values('weight', ascending=False)\n",
    "sorting_very = sorting_very.groupby('text').sum().sort_values('weight', ascending=False)\n",
    "sorting_nice = sorting_nice.groupby('text').sum().sort_values('weight', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_x</th>\n",
       "      <th>count_y</th>\n",
       "      <th>count_z</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>better off</th>\n",
       "      <td>25</td>\n",
       "      <td>88</td>\n",
       "      <td>113</td>\n",
       "      <td>35.123894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better to</th>\n",
       "      <td>40</td>\n",
       "      <td>107</td>\n",
       "      <td>147</td>\n",
       "      <td>30.537415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better acting</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>21.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better script</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>21.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better movie</th>\n",
       "      <td>21</td>\n",
       "      <td>63</td>\n",
       "      <td>84</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better job</th>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>15.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better actors</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>14.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better spent</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>13.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better things</th>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>12.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better if</th>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>88</td>\n",
       "      <td>11.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better known</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>11.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better for</th>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better luck</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better material</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>8.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better suited</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>8.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better idea</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>7.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better production</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better or</th>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>7.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better here</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better life</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>6.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better from</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>6.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better ways</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better not</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>5.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better story</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>5.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better be</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better made</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>4.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better after</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>4.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better films</th>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>4.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better person</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better man</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better graphics</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better romantic</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better reputation</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better program</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better form</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better fitted</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better setting</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better filming</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better shot</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better show</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better jobs</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better silent</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better figure</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better experience</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better sound</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better example</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better option</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better portrayed</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better effect</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better editing</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better study</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better earlier</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better documentary</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better directed</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better described</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better deals</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better rating</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better days</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better dancer</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better rapper</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count_x  count_y  count_z     weight\n",
       "text                                                    \n",
       "better off               25       88      113  35.123894\n",
       "better to                40      107      147  30.537415\n",
       "better acting             4       32       36  21.777778\n",
       "better script             2       27       29  21.551724\n",
       "better movie             21       63       84  21.000000\n",
       "better job               17       49       66  15.515152\n",
       "better actors             2       20       22  14.727273\n",
       "better spent              2       19       21  13.761905\n",
       "better things             8       30       38  12.736842\n",
       "better if                28       60       88  11.636364\n",
       "better known             30        9       39  11.307692\n",
       "better for               35       14       49   9.000000\n",
       "better luck               2       14       16   9.000000\n",
       "better material           2       13       15   8.066667\n",
       "better suited             2       13       15   8.066667\n",
       "better idea               1       10       11   7.363636\n",
       "better production         2       12       14   7.142857\n",
       "better or                29       12       41   7.048780\n",
       "better here               9        1       10   6.400000\n",
       "better life              15        4       19   6.368421\n",
       "better from               4       15       19   6.368421\n",
       "better ways               1        8        9   5.444444\n",
       "better not                3       12       15   5.400000\n",
       "better story              3       12       15   5.400000\n",
       "better be                 2       10       12   5.333333\n",
       "better made               4       13       17   4.764706\n",
       "better after              3       11       14   4.571429\n",
       "better films             20       36       56   4.571429\n",
       "better person             7        1        8   4.500000\n",
       "better man                9        2       11   4.454545\n",
       "...                     ...      ...      ...        ...\n",
       "better graphics           1        1        2   0.000000\n",
       "better romantic           1        1        2   0.000000\n",
       "better reputation         1        1        2   0.000000\n",
       "better program            1        1        2   0.000000\n",
       "better form               1        1        2   0.000000\n",
       "better fitted             1        1        2   0.000000\n",
       "better setting            1        1        2   0.000000\n",
       "better filming            1        1        2   0.000000\n",
       "better shot               1        1        2   0.000000\n",
       "better show               2        2        4   0.000000\n",
       "better jobs               1        1        2   0.000000\n",
       "better silent             1        1        2   0.000000\n",
       "better figure             1        1        2   0.000000\n",
       "better experience         2        2        4   0.000000\n",
       "better sound              3        3        6   0.000000\n",
       "better example            2        2        4   0.000000\n",
       "better option             1        1        2   0.000000\n",
       "better portrayed          1        1        2   0.000000\n",
       "better effect             3        3        6   0.000000\n",
       "better editing            1        1        2   0.000000\n",
       "better study              1        1        2   0.000000\n",
       "better earlier            1        1        2   0.000000\n",
       "better documentary        1        1        2   0.000000\n",
       "better directed           1        1        2   0.000000\n",
       "better described          1        1        2   0.000000\n",
       "better deals              1        1        2   0.000000\n",
       "better rating             2        2        4   0.000000\n",
       "better days               4        4        8   0.000000\n",
       "better dancer             1        1        2   0.000000\n",
       "better rapper             1        1        2   0.000000\n",
       "\n",
       "[212 rows x 4 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorting_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = list(sorting.head(3000).index)\n",
    "#b = list(sorting_not.head(400).index)\n",
    "#c = list(sorting_good.head(400).index)\n",
    "#d = list(sorting_best.head(150).index)\n",
    "#e = list(sorting_bad.head(184).index)\n",
    "#f = list(sorting_like.head(251).index)\n",
    "#g = list(sorting_better.head(150).index)\n",
    "#h = list(sorting_very.head(220).index)\n",
    "#i = list(sorting_nice.head(95).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_single = 80.0\n",
    "weight_for_double = 5.0\n",
    "\n",
    "a = list(sorting.loc[sorting['weight']>=weight_for_single].index)\n",
    "b = list(sorting_not.loc[sorting_not['weight']>=weight_for_double].index)\n",
    "c = list(sorting_good.loc[sorting_good['weight']>=weight_for_double].index)\n",
    "d = list(sorting_best.loc[sorting_best['weight']>=weight_for_double].index)\n",
    "e = list(sorting_bad.loc[sorting_bad['weight']>=weight_for_double].index)\n",
    "f = list(sorting_like.loc[sorting_like['weight']>=weight_for_double].index)\n",
    "g = list(sorting_better.loc[sorting_better['weight']>=weight_for_double].index)\n",
    "h = list(sorting_very.loc[sorting_very['weight']>=weight_for_double].index)\n",
    "i = list(sorting_nice.loc[sorting_nice['weight']>=weight_for_double].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_max = a+b+c+d+e+f+g+h+i\n",
    "length = len(pos_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad\n",
      "1 ?\n",
      "2 worst\n",
      "3 great\n",
      "4 and\n",
      "5 awful\n",
      "6 waste\n",
      "7 no\n",
      "8 his\n",
      "9 excellent\n",
      "10 terrible\n",
      "11 movie\n",
      "12 stupid\n",
      "13 best\n",
      "14 love\n",
      "15 boring\n",
      "16 worse\n",
      "17 wonderful\n",
      "18 as\n",
      "19 just\n",
      "20 nothing\n",
      "21 horrible\n",
      "22 poor\n",
      "23 even\n",
      "24 minutes\n",
      "25 crap\n",
      "26 perfect\n",
      "27 why\n",
      "28 supposed\n",
      "29 amazing\n",
      "30 is\n",
      "31 life\n",
      "32 poorly\n",
      "33 very\n",
      "34 plot\n",
      "35 this\n",
      "36 beautiful\n",
      "37 in\n",
      "38 well\n",
      "39 lame\n",
      "40 of\n",
      "41 also\n",
      "42 script\n",
      "43 don't\n",
      "44 acting\n",
      "45 was\n",
      "46 ridiculous\n",
      "47 loved\n",
      "48 favorite\n",
      "49 brilliant\n",
      "50 or\n",
      "51 pointless\n",
      "52 any\n",
      "53 money\n",
      "54 oh\n",
      "55 dull\n",
      "56 annoying\n",
      "57 they\n",
      "58 both\n",
      "59 her\n",
      "60 avoid\n",
      "61 badly\n",
      "62 fantastic\n",
      "63 superb\n",
      "64 thing\n",
      "65 performance\n",
      "66 highly\n",
      "67 mess\n",
      "68 if\n",
      "69 wasted\n",
      "70 the\n",
      "71 young\n",
      "72 laughable\n",
      "73 world\n",
      "74 always\n",
      "75 cheap\n",
      "76 instead\n",
      "77 heart\n",
      "78 least\n",
      "79 there\n",
      "80 so\n",
      "81 today\n",
      "82 pathetic\n",
      "83 make\n",
      "84 guy\n",
      "85 could\n",
      "86 he\n",
      "87 then\n",
      "88 like\n",
      "89 reason\n",
      "90 have\n",
      "91 performances\n",
      "92 unless\n",
      "93 series\n",
      "94 dumb\n",
      "95 family\n",
      "96 only\n",
      "97 couldn't\n",
      "98 redeeming\n",
      "99 beautifully\n",
      "100 years\n",
      "101 didn't\n",
      "102 garbage\n",
      "103 anything\n",
      "104 save\n",
      "105 gore\n",
      "106 enjoyed\n",
      "107 fails\n",
      "108 i'm\n",
      "109 father\n",
      "110 powerful\n",
      "111 unfunny\n",
      "112 off\n",
      "113 story\n",
      "114 would\n",
      "115 touching\n",
      "116 still\n",
      "117 decent\n",
      "118 job\n",
      "119 wonderfully\n",
      "120 unfortunately\n",
      "121 predictable\n",
      "122 wasn't\n",
      "123 joke\n",
      "124 low\n",
      "125 perfectly\n",
      "126 do\n",
      "127 stewart\n",
      "128 mean\n",
      "129 each\n",
      "130 terrific\n",
      "131 oscar\n",
      "132 strong\n",
      "133 true\n",
      "134 role\n",
      "135 fun\n",
      "136 excuse\n",
      "137 zombies\n",
      "138 noir\n",
      "139 looks\n",
      "140 outstanding\n",
      "141 classic\n",
      "142 attempt\n",
      "143 ok\n",
      "144 be\n",
      "145 greatest\n",
      "146 sorry\n",
      "147 better\n",
      "148 half\n",
      "149 idea\n",
      "150 bunch\n",
      "151 guess\n",
      "152 different\n",
      "153 there's\n",
      "154 will\n",
      "155 definitely\n",
      "156 someone\n",
      "157 sucks\n",
      "158 unique\n",
      "159 war\n",
      "160 beauty\n",
      "161 him\n",
      "162 victoria\n",
      "163 shows\n",
      "164 episodes\n",
      "165 she\n",
      "166 gives\n",
      "167 has\n",
      "168 budget\n",
      "169 bother\n",
      "170 lousy\n",
      "171 fake\n",
      "172 recommended\n",
      "173 especially\n",
      "174 blah\n",
      "175 delightful\n",
      "176 apparently\n",
      "177 not\n",
      "178 man\n",
      "179 wooden\n",
      "180 moving\n",
      "181 horror\n",
      "182 own\n",
      "183 atrocious\n",
      "184 were\n",
      "185 works\n",
      "186 journey\n",
      "187 unbelievable\n",
      "188 disappointing\n",
      "189 season\n",
      "190 either\n",
      "191 seriously\n",
      "192 gem\n",
      "193 disappointment\n",
      "194 plays\n",
      "195 simple\n",
      "196 captures\n",
      "197 whatsoever\n",
      "198 wrong\n",
      "199 stunning\n",
      "200 seagal\n",
      "201 something\n",
      "202 trash\n",
      "203 with\n",
      "204 enjoy\n",
      "205 mediocre\n",
      "206 boll\n",
      "207 bored\n",
      "208 relationship\n",
      "209 friendship\n",
      "210 problem\n",
      "211 mst3k\n",
      "212 incredible\n",
      "213 subtle\n",
      "214 masterpiece\n",
      "215 rare\n",
      "216 awesome\n",
      "217 insult\n",
      "218 between\n",
      "219 weak\n",
      "220 cliché\n",
      "221 remotely\n",
      "222 sweet\n",
      "223 dreadful\n",
      "224 hour\n",
      "225 finest\n",
      "226 city\n",
      "227 none\n",
      "228 played\n",
      "229 amateurish\n",
      "230 should\n",
      "231 can't\n",
      "232 welles\n",
      "233 its\n",
      "234 flat\n",
      "235 underrated\n",
      "236 that's\n",
      "237 fine\n",
      "238 supporting\n",
      "239 failed\n",
      "240 plain\n",
      "241 br\n",
      "242 lives\n",
      "243 kelly\n",
      "244 portrayal\n",
      "245 realistic\n",
      "246 refreshing\n",
      "247 magnificent\n",
      "248 tedious\n",
      "249 uninteresting\n",
      "250 incoherent\n",
      "251 rubbish\n",
      "252 brilliantly\n",
      "253 silly\n",
      "254 emotions\n",
      "255 many\n",
      "256 effects\n",
      "257 enjoyable\n",
      "258 random\n",
      "259 zombie\n",
      "260 flick\n",
      "261 matthau\n",
      "262 powell\n",
      "263 john\n",
      "264 lack\n",
      "265 memorable\n",
      "266 looked\n",
      "267 embarrassing\n",
      "268 your\n",
      "269 tale\n",
      "270 vampires\n",
      "271 completely\n",
      "272 brain\n",
      "273 wouldn't\n",
      "274 ??\n",
      "275 solid\n",
      "276 tony\n",
      "277 may\n",
      "278 actually\n",
      "279 human\n",
      "280 unconvincing\n",
      "281 nudity\n",
      "282 favourite\n",
      "283 remarkable\n",
      "284 most\n",
      "285 original\n",
      "286 please\n",
      "287 trying\n",
      "288 crappy\n",
      "289 bourne\n",
      "290 except\n",
      "291 freedom\n",
      "292 paulie\n",
      "293 doesn't\n",
      "294 watching\n",
      "295 nowhere\n",
      "296 sex\n",
      "297 okay\n",
      "298 bond\n",
      "299 bland\n",
      "300 paul\n",
      "301 existent\n",
      "302 uwe\n",
      "303 romantic\n",
      "304 pile\n",
      "305 nancy\n",
      "306 wasting\n",
      "307 effort\n",
      "308 painful\n",
      "309 who\n",
      "310 premise\n",
      "311 perfection\n",
      "312 by\n",
      "313 future\n",
      "314 marie\n",
      "315 maybe\n",
      "316 total\n",
      "317 saying\n",
      "318 felix\n",
      "319 helps\n",
      "320 unwatchable\n",
      "321 flawless\n",
      "322 sinatra\n",
      "323 breathtaking\n",
      "324 fascinating\n",
      "325 later\n",
      "326 want\n",
      "327 killer\n",
      "328 seemed\n",
      "329 seconds\n",
      "330 ???\n",
      "331 monster\n",
      "332 suck\n",
      "333 charming\n",
      "334 been\n",
      "335 complex\n",
      "336 honestly\n",
      "337 costs\n",
      "338 episode\n",
      "339 had\n",
      "340 ugly\n",
      "341 pretty\n",
      "342 vampire\n",
      "343 day\n",
      "344 tried\n",
      "345 tragic\n",
      "346 because\n",
      "347 stinker\n",
      "348 provides\n",
      "349 screaming\n",
      "350 forgettable\n",
      "351 harry\n",
      "352 intense\n",
      "353 write\n",
      "354 superbly\n",
      "355 atmosphere\n",
      "356 stupidity\n",
      "357 enough\n",
      "358 90\n",
      "359 new\n",
      "360 drivel\n",
      "361 isn't\n",
      "362 although\n",
      "363 jackie\n",
      "364 favorites\n",
      "365 hell\n",
      "366 yeah\n",
      "367 horrid\n",
      "368 rent\n",
      "369 themes\n",
      "370 easy\n",
      "371 paid\n",
      "372 emotional\n",
      "373 lincoln\n",
      "374 gundam\n",
      "375 god\n",
      "376 mildred\n",
      "377 jack\n",
      "378 gandhi\n",
      "379 boredom\n",
      "380 adventure\n",
      "381 porn\n",
      "382 did\n",
      "383 astaire\n",
      "384 quite\n",
      "385 not even\n",
      "386 not funny\n",
      "387 not worth\n",
      "388 not waste\n",
      "389 not recommend\n",
      "390 not enough\n",
      "391 not that\n",
      "392 not scary\n",
      "393 not good\n",
      "394 not one\n",
      "395 not watch\n",
      "396 not make\n",
      "397 not much\n",
      "398 not save\n",
      "399 not be\n",
      "400 not recommended\n",
      "401 not perfect\n",
      "402 not in\n",
      "403 not believe\n",
      "404 not always\n",
      "405 not seen\n",
      "406 not interesting\n",
      "407 not your\n",
      "408 not very\n",
      "409 not believable\n",
      "410 not many\n",
      "411 not as\n",
      "412 not about\n",
      "413 not this\n",
      "414 not without\n",
      "415 not entertaining\n",
      "416 not disappointed\n",
      "417 not quite\n",
      "418 not see\n",
      "419 not saying\n",
      "420 not act\n",
      "421 not worthy\n",
      "422 not work\n",
      "423 not just\n",
      "424 not available\n",
      "425 not only\n",
      "426 not afraid\n",
      "427 not kidding\n",
      "428 not fun\n",
      "429 not a\n",
      "430 not sure\n",
      "431 not because\n",
      "432 not for\n",
      "433 not buy\n",
      "434 not easy\n",
      "435 not disappoint\n",
      "436 not by\n",
      "437 not laughing\n",
      "438 not awful\n",
      "439 not there\n",
      "440 not like\n",
      "441 not unlike\n",
      "442 not bother\n",
      "443 not to\n",
      "444 not heard\n",
      "445 not hesitate\n",
      "446 not miss\n",
      "447 not is\n",
      "448 not caring\n",
      "449 not over\n",
      "450 not so\n",
      "451 not meet\n",
      "452 not under\n",
      "453 not help\n",
      "454 not horrible\n",
      "455 not all\n",
      "456 not at\n",
      "457 not usually\n",
      "458 not tell\n",
      "459 not often\n",
      "460 not of\n",
      "461 not knowing\n",
      "462 not helped\n",
      "463 not surprising\n",
      "464 not cast\n",
      "465 not developed\n",
      "466 not bad\n",
      "467 not comment\n",
      "468 not joking\n",
      "469 not fail\n",
      "470 not against\n",
      "471 not acting\n",
      "472 not merely\n",
      "473 not true\n",
      "474 not shown\n",
      "475 not forget\n",
      "476 good as\n",
      "477 good idea\n",
      "478 good thing\n",
      "479 good and\n",
      "480 good job\n",
      "481 good times\n",
      "482 good points\n",
      "483 good about\n",
      "484 good film\n",
      "485 good either\n",
      "486 good actors\n",
      "487 good ideas\n",
      "488 good looking\n",
      "489 good show\n",
      "490 good too\n",
      "491 good reviews\n",
      "492 good little\n",
      "493 good parts\n",
      "494 good laugh\n",
      "495 good performances\n",
      "496 good friends\n",
      "497 good part\n",
      "498 good premise\n",
      "499 good it\n",
      "500 good family\n",
      "501 good vs\n",
      "502 good lord\n",
      "503 good thriller\n",
      "504 good that\n",
      "505 good watch\n",
      "506 good friend\n",
      "507 good is\n",
      "508 good sign\n",
      "509 good fun\n",
      "510 good cinema\n",
      "511 good grief\n",
      "512 good bad\n",
      "513 good horror\n",
      "514 good money\n",
      "515 good scene\n",
      "516 good review\n",
      "517 good mix\n",
      "518 good solid\n",
      "519 good for\n",
      "520 good b\n",
      "521 good company\n",
      "522 good gore\n",
      "523 good cop\n",
      "524 good versus\n",
      "525 best of\n",
      "526 best film\n",
      "527 best movies\n",
      "528 best films\n",
      "529 best movie\n",
      "530 best performances\n",
      "531 best supporting\n",
      "532 best performance\n",
      "533 best work\n",
      "534 best in\n",
      "535 best actress\n",
      "536 best ever\n",
      "537 best known\n",
      "538 best picture\n",
      "539 best role\n",
      "540 best i've\n",
      "541 best friend\n",
      "542 best show\n",
      "543 best episodes\n",
      "544 best tv\n",
      "545 best they\n",
      "546 best one\n",
      "547 best part\n",
      "548 best and\n",
      "549 best comedy\n",
      "550 best actor\n",
      "551 best bit\n",
      "552 best music\n",
      "553 best action\n",
      "554 best out\n",
      "555 best shows\n",
      "556 best comedies\n",
      "557 best horror\n",
      "558 best director\n",
      "559 best scenes\n",
      "560 best left\n",
      "561 best animated\n",
      "562 best thing\n",
      "563 best with\n",
      "564 best cinematography\n",
      "565 best for\n",
      "566 best actors\n",
      "567 best series\n",
      "568 best story\n",
      "569 best writing\n",
      "570 best to\n",
      "571 best screenplay\n",
      "572 bad movie\n",
      "573 bad acting\n",
      "574 bad movies\n",
      "575 bad as\n",
      "576 bad film\n",
      "577 bad it\n",
      "578 bad that\n",
      "579 bad and\n",
      "580 bad this\n",
      "581 bad enough\n",
      "582 bad it's\n",
      "583 bad script\n",
      "584 bad i\n",
      "585 bad films\n",
      "586 bad the\n",
      "587 bad in\n",
      "588 bad writing\n",
      "589 bad for\n",
      "590 bad taste\n",
      "591 bad guys\n",
      "592 bad plot\n",
      "593 bad but\n",
      "594 bad directing\n",
      "595 bad horror\n",
      "596 bad guy\n",
      "597 bad actors\n",
      "598 bad joke\n",
      "599 bad dialogue\n",
      "600 bad one\n",
      "601 bad they\n",
      "602 bad actor\n",
      "603 bad idea\n",
      "604 bad is\n",
      "605 bad jokes\n",
      "606 bad to\n",
      "607 bad bad\n",
      "608 bad by\n",
      "609 bad ones\n",
      "610 bad news\n",
      "611 bad can\n",
      "612 bad camera\n",
      "613 bad cinema\n",
      "614 bad dialog\n",
      "615 bad if\n",
      "616 bad direction\n",
      "617 bad from\n",
      "618 bad editing\n",
      "619 bad when\n",
      "620 bad special\n",
      "621 bad a\n",
      "622 bad like\n",
      "623 bad on\n",
      "624 bad you\n",
      "625 bad story\n",
      "626 bad episode\n",
      "627 bad too\n",
      "628 bad b\n",
      "629 bad effects\n",
      "630 bad made\n",
      "631 bad version\n",
      "632 bad comedy\n",
      "633 bad thing\n",
      "634 bad because\n",
      "635 bad way\n",
      "636 like a\n",
      "637 like they\n",
      "638 like watching\n",
      "639 like this\n",
      "640 like an\n",
      "641 like i\n",
      "642 like someone\n",
      "643 like most\n",
      "644 like many\n",
      "645 like beckham\n",
      "646 like anything\n",
      "647 like she's\n",
      "648 like there\n",
      "649 like he's\n",
      "650 like it\n",
      "651 like it's\n",
      "652 like she\n",
      "653 like they're\n",
      "654 like he\n",
      "655 like when\n",
      "656 like about\n",
      "657 like saying\n",
      "658 like some\n",
      "659 like film\n",
      "660 like citizen\n",
      "661 like one\n",
      "662 like trying\n",
      "663 like few\n",
      "664 like creature\n",
      "665 like something\n",
      "666 better off\n",
      "667 better to\n",
      "668 better acting\n",
      "669 better script\n",
      "670 better movie\n",
      "671 better job\n",
      "672 better actors\n",
      "673 better spent\n",
      "674 better things\n",
      "675 better if\n",
      "676 better known\n",
      "677 better for\n",
      "678 better luck\n",
      "679 better material\n",
      "680 better suited\n",
      "681 better idea\n",
      "682 better production\n",
      "683 better or\n",
      "684 better here\n",
      "685 better life\n",
      "686 better from\n",
      "687 better ways\n",
      "688 better not\n",
      "689 better story\n",
      "690 better be\n",
      "691 very well\n",
      "692 very good\n",
      "693 very bad\n",
      "694 very entertaining\n",
      "695 very different\n",
      "696 very enjoyable\n",
      "697 very poor\n",
      "698 very disappointed\n",
      "699 very funny\n",
      "700 very realistic\n",
      "701 very moving\n",
      "702 very little\n",
      "703 very believable\n",
      "704 very disappointing\n",
      "705 very boring\n",
      "706 very much\n",
      "707 very weak\n",
      "708 very best\n",
      "709 very real\n",
      "710 very poorly\n",
      "711 very worst\n",
      "712 very fine\n",
      "713 very strong\n",
      "714 very satisfying\n",
      "715 very powerful\n",
      "716 very interesting\n",
      "717 very predictable\n",
      "718 very low\n",
      "719 very unique\n",
      "720 very badly\n",
      "721 very nice\n",
      "722 very other\n",
      "723 very first\n",
      "724 very exciting\n",
      "725 very second\n",
      "726 very annoying\n",
      "727 very dull\n",
      "728 very cheap\n",
      "729 very sweet\n",
      "730 very impressed\n",
      "731 very average\n",
      "732 very human\n",
      "733 very natural\n",
      "734 very effective\n",
      "735 very fun\n",
      "736 very impressive\n",
      "737 very special\n",
      "738 very easy\n",
      "739 very personal\n",
      "740 very cool\n",
      "741 very intelligent\n",
      "742 very true\n",
      "743 very cheesy\n",
      "744 very emotional\n",
      "745 very five\n",
      "746 very level\n",
      "747 very episode\n",
      "748 very stupid\n",
      "749 very unusual\n",
      "750 very day\n",
      "751 very close\n",
      "752 very clever\n",
      "753 very likable\n",
      "754 very nicely\n",
      "755 very cliché\n",
      "756 very convincing\n",
      "757 very copy\n",
      "758 very least\n",
      "759 very similar\n",
      "760 very single\n",
      "761 very high\n",
      "762 very wrong\n",
      "763 very amusing\n",
      "764 very happy\n",
      "765 very popular\n",
      "766 very intriguing\n",
      "767 very complex\n",
      "768 very tight\n",
      "769 very pleased\n",
      "770 very smart\n",
      "771 very original\n",
      "772 very cleverly\n",
      "773 very solid\n",
      "774 very charming\n",
      "775 very tense\n",
      "776 very that\n",
      "777 very rich\n",
      "778 very underrated\n",
      "779 very time\n",
      "780 very glad\n",
      "781 very memorable\n",
      "782 very viewer\n",
      "783 very dumb\n",
      "784 very bland\n",
      "785 very lame\n",
      "786 very major\n",
      "787 very confusing\n",
      "788 very and\n",
      "789 very cute\n",
      "790 very excited\n",
      "791 very creepy\n",
      "792 very surreal\n",
      "793 very tame\n",
      "794 very quiet\n",
      "795 very fan\n",
      "796 very neat\n",
      "797 very unfortunate\n",
      "798 very unfunny\n",
      "799 very sunday\n",
      "800 very pleasant\n",
      "801 very colorful\n",
      "802 very thought\n",
      "803 very basic\n",
      "804 very loosely\n",
      "805 very emotion\n",
      "806 very rare\n",
      "807 very intense\n",
      "808 very great\n",
      "809 very watchable\n",
      "810 nice little\n",
      "811 nice shots\n",
      "812 nice movie\n",
      "813 nice pace\n",
      "814 nice job\n",
      "815 nice try\n",
      "816 nice to\n",
      "817 nice story\n",
      "818 nice scenery\n",
      "819 nice way\n"
     ]
    }
   ],
   "source": [
    "dictonary = {}\n",
    "for i in range(len(pos_max)):\n",
    "    print(i,pos_max[i])\n",
    "    dictonary[pos_max[i]]=i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract words from .txt for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "path = '/Users/felixrolf/PycharmProjects/my_voice_predictor/data/movies/pos_train/'\n",
    "all_files = glob.glob(path + '*.txt')\n",
    "\n",
    "for filename in all_files:\n",
    "    matrix_row = np.zeros(length, dtype = int)\n",
    "    file = open(filename, 'r')\n",
    "    for line in file:\n",
    "        words = rgx_pos.findall(line) + rgx_not.findall(line) + rgx_good.findall(line) + rgx_best.findall(line) + rgx_bad.findall(line) + rgx_like.findall(line) + rgx_better.findall(line) + rgx_very.findall(line) + rgx_nice.findall(line)\n",
    "        for word in words:\n",
    "            if word in dictonary:\n",
    "                matrix_row[dictonary[word]] += 1\n",
    "    matrix.append(matrix_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.DataFrame(matrix)\n",
    "df_pos.columns = [pos_max]\n",
    "df_pos['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_neg = []\n",
    "path = '/Users/felixrolf/PycharmProjects/my_voice_predictor/data/movies/neg_train/'\n",
    "all_files = glob.glob(path + '*.txt')\n",
    "\n",
    "for filename in all_files:\n",
    "    matrix_row = np.zeros(length, dtype = int)\n",
    "    file = open(filename, 'r')\n",
    "    for line in file:\n",
    "        words = rgx_neg.findall(line) + rgx_not_n.findall(line) + rgx_good_n.findall(line) + rgx_best_n.findall(line) + rgx_bad_n.findall(line) + rgx_like_n.findall(line) + rgx_better_n.findall(line) + rgx_very_n.findall(line) + rgx_nice_n.findall(line)\n",
    "        for word in words:\n",
    "            if word in dictonary:\n",
    "                matrix_row[dictonary[word]] += 1\n",
    "    matrix_neg.append(matrix_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = pd.DataFrame(matrix_neg)\n",
    "df_neg.columns = [pos_max]\n",
    "df_neg['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_pos,df_neg],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_test = []\n",
    "path = '/Users/felixrolf/PycharmProjects/my_voice_predictor/data/movies/pos_test/'\n",
    "all_files = glob.glob(path + '*.txt')\n",
    "\n",
    "for filename in all_files:\n",
    "    matrix_row = np.zeros(length, dtype = int)\n",
    "    file = open(filename, 'r')\n",
    "    for line in file:\n",
    "        words = rgx_pos.findall(line) + rgx_not.findall(line) + rgx_good.findall(line) + rgx_best.findall(line) + rgx_bad.findall(line) + rgx_like.findall(line) + rgx_better.findall(line) + rgx_very.findall(line) + rgx_nice.findall(line)\n",
    "        for word in words:\n",
    "            if word in dictonary:\n",
    "                matrix_row[dictonary[word]] += 1\n",
    "    matrix_test.append(matrix_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_t = pd.DataFrame(matrix_test)\n",
    "df_pos_t.columns = [pos_max]\n",
    "df_pos_t['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_neg_test = []\n",
    "path = '/Users/felixrolf/PycharmProjects/my_voice_predictor/data/movies/neg_test/'\n",
    "all_files = glob.glob(path + '*.txt')\n",
    "\n",
    "for filename in all_files:\n",
    "    matrix_row = np.zeros(length, dtype = int)\n",
    "    file = open(filename, 'r')\n",
    "    for line in file:\n",
    "        words = rgx_neg.findall(line) + rgx_not_n.findall(line) + rgx_good_n.findall(line) + rgx_best_n.findall(line) + rgx_bad_n.findall(line) + rgx_like_n.findall(line) + rgx_better_n.findall(line) + rgx_very_n.findall(line) + rgx_nice_n.findall(line)\n",
    "        for word in words:\n",
    "            if word in dictonary:\n",
    "                matrix_row[dictonary[word]] += 1\n",
    "    matrix_neg_test.append(matrix_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg_t = pd.DataFrame(matrix_neg_test)\n",
    "df_neg_t.columns = [pos_max]\n",
    "df_neg_t['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_pos_t,df_neg_t],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('thilo_und_felix_imdb_train_auto.csv', index=False)\n",
    "df_test.to_csv('thilo_und_felix_imdb_test_auto.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixrolf/anaconda3/envs/my_voice_predictor/lib/python3.6/site-packages/pandas/core/generic.py:3812: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train['target']\n",
    "X_train = df_train.drop(['target'], axis=1)\n",
    "y_test = df_test['target']\n",
    "X_test = df_test.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixrolf/anaconda3/envs/my_voice_predictor/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/felixrolf/anaconda3/envs/my_voice_predictor/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train:\t 0.91376\n",
      "Accuracy test:\t 0.87632\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "error_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(f'Accuracy train:\\t {metrics.accuracy_score(y_train, y_pred_train)}')\n",
    "error_train = mean_squared_error(y_test, y_pred_test)\n",
    "print(f'Accuracy test:\\t {metrics.accuracy_score(y_test, y_pred_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dump, y_train, y_dump = train_test_split(X_train, y_train, test_size=0.5)\n",
    "X_test, X_dump_2, y_test, y_dump_2 = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixrolf/anaconda3/envs/my_voice_predictor/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train:\t 0.88744\n",
      "Accuracy test:\t 0.84192\n"
     ]
    }
   ],
   "source": [
    "sv = svm.SVC(gamma='scale')\n",
    "sv.fit(X_train, y_train)\n",
    "y_pred_train = sv.predict(X_train)\n",
    "y_pred_test = sv.predict(X_test)\n",
    "error_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(f'Accuracy train:\\t {metrics.accuracy_score(y_train, y_pred_train)}')\n",
    "error_train = mean_squared_error(y_test, y_pred_test)\n",
    "print(f'Accuracy test:\\t {metrics.accuracy_score(y_test, y_pred_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
