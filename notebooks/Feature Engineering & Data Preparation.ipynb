{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files from data\n",
    "\n",
    "load all the articles from local storage (new_data & data) and prepare the tables for the subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The for-loop gathers all the .csv files within the data directory, concats and labels them and then returns a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = {\n",
    "    1: 'politik', 2: 'wirtschaft', 3: 'finanzen', 4: 'feuilleton', 5: 'sport', 6: 'gesellschaft', 7: 'stil', \n",
    "    8: 'technik-motor', 9: 'wissen', 10: 'reise', 11: 'beruf-chance'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tables(category):\n",
    "    raw_articles = []\n",
    "    if category is 'aktuell':\n",
    "        path = f\"../new_data/aktuell/\"\n",
    "    else:\n",
    "        path = f\"../new_data/{category}/\"\n",
    "        \n",
    "    all_files = glob.glob(path + '*.csv')\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        raw_articles.append(df)\n",
    "    faz_articles = pd.concat(raw_articles, axis=0, ignore_index=True)\n",
    "    faz_articles['label'] = category\n",
    "\n",
    "    return faz_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Generate Test and Train Data\n",
    "\n",
    "**This for-loop goes through the data frames built in the first step and then collects the words from each entry in a list.**\n",
    "\n",
    "## Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for key, value in category.items():\n",
    "    raw_faz = build_tables(value)\n",
    "    frames.append(raw_faz)\n",
    "    faz_train = pd.concat(frames, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_train = faz_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faz_train_seq = faz_train['detailed']\n",
    "#faz_train_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faz_train[faz_train['label'] == 'aktuell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>detailed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beruf-chance</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feuilleton</th>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finanzen</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gesellschaft</th>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politik</th>\n",
       "      <td>382</td>\n",
       "      <td>382</td>\n",
       "      <td>382</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reise</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stil</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technik-motor</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wirtschaft</th>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wissen</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               link  published  title  detailed\n",
       "label                                          \n",
       "beruf-chance     32         32     32        32\n",
       "feuilleton      171        171    171       171\n",
       "finanzen        119        119    119       119\n",
       "gesellschaft    246        246    246       246\n",
       "politik         382        382    382       382\n",
       "reise            16         16     16        16\n",
       "sport           328        328    328       328\n",
       "stil             44         44     44        44\n",
       "technik-motor    44         44     44        44\n",
       "wirtschaft      246        246    246       246\n",
       "wissen           63         63     63        63"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_train.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train data in 'politik' and 'rest':\n",
    "\n",
    "This step is for the sake of labelling the subsequant data and to get an idea of the data distribution (**'Politics' make up about 17% of the train data**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_train.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_pol = faz_train[faz_train.label == 'politik']\n",
    "faz_sport = faz_train[faz_train.label == 'sport']\n",
    "faz_eco = faz_train[faz_train.label == 'wirtschaft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_train_2 = faz_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_train_2 = faz_train_2[faz_train_2.label != 'politik']\n",
    "faz_train_2 = faz_train_2[faz_train_2.label != 'sport']\n",
    "faz_train_2 = faz_train_2[faz_train_2.label != 'wirtschaft']\n",
    "faz_rem = faz_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_rem.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>detailed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beruf-chance</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feuilleton</th>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finanzen</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gesellschaft</th>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reise</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stil</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technik-motor</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wissen</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               link  published  title  detailed\n",
       "label                                          \n",
       "beruf-chance     32         32     32        32\n",
       "feuilleton      171        171    171       171\n",
       "finanzen        119        119    119       119\n",
       "gesellschaft    246        246    246       246\n",
       "reise            16         16     16        16\n",
       "stil             44         44     44        44\n",
       "technik-motor    44         44     44        44\n",
       "wissen           63         63     63        63"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_rem.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build feature word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgx_singles = re.compile(\"([\\w][\\w']*[\\w])\")\n",
    "rgx_doubles = re.compile(\"([\\w][\\w']*[\\w] +[\\w][\\w']*[\\w])\")\n",
    "rgx_triples = re.compile(\"([\\w][\\w']*[\\w] +[\\w][\\w']*[\\w] +[\\w][\\w']*[\\w])\")\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for index, row in faz_train.iterrows():\n",
    "    line = row['detailed'].translate(translator)\n",
    "    words += rgx_singles.findall(line)\n",
    "    words += rgx_doubles.findall(line)\n",
    "    words += rgx_triples.findall(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = pd.DataFrame(words, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for index, row in faz_train.iterrows():\n",
    "    line = row['title'].translate(translator)\n",
    "    titles += rgx_singles.findall(line)\n",
    "    titles += rgx_doubles.findall(line)\n",
    "    titles += rgx_triples.findall(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = pd.DataFrame(titles, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped = [word_list, title_list]\n",
    "merged = pd.concat(scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all words that are in the stopword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = merged['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = pd.read_csv('/Users/torben/PycharmProjects/toolbox/stopwords/stopwords.csv', index_col=None, header=0)\n",
    "stopwordupper = pd.read_csv('/Users/torben/PycharmProjects/toolbox/stopwords/stopwordsupper.csv', index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopword['words'].tolist()\n",
    "stopwordsupper = stopwordupper['words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [word for word in merged_list if word not in stopwords]\n",
    "fin_feat_list = [word for word in feature_list if word not in stopwordsupper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(fin_feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.groupby('words').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.sort_values('count', ascending=False)\n",
    "features_sort = features.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in der',\n",
       " 'Jahre',\n",
       " 'NotreDame',\n",
       " 'Trump',\n",
       " 'Jahren',\n",
       " 'Deutschland',\n",
       " 'Liveticker',\n",
       " 'Berlin',\n",
       " 'deutschen',\n",
       " 'Paris',\n",
       " 'Welt',\n",
       " 'Präsident',\n",
       " 'Trainer',\n",
       " 'Zeit',\n",
       " 'Menschen',\n",
       " 'zeigt',\n",
       " 'für die',\n",
       " 'Brexit',\n",
       " 'Assange',\n",
       " 'deutsche',\n",
       " 'League',\n",
       " 'EU',\n",
       " 'Jahr',\n",
       " 'Polizei',\n",
       " 'Donald',\n",
       " 'spricht',\n",
       " 'Bayern',\n",
       " 'May',\n",
       " 'Bundesliga',\n",
       " 'Julian',\n",
       " 'Spiel',\n",
       " 'für den',\n",
       " 'Kathedrale',\n",
       " 'Nowitzki',\n",
       " 'offenbar',\n",
       " 'AfD',\n",
       " 'großen',\n",
       " 'Brand',\n",
       " 'Augsburg',\n",
       " 'FC',\n",
       " '2019',\n",
       " 'of',\n",
       " 'Euro',\n",
       " 'Champions',\n",
       " 'Kinder',\n",
       " 'lässt',\n",
       " 'Deutschen',\n",
       " 'bei der',\n",
       " 'lange',\n",
       " 'Thrones',\n",
       " 'Merkel',\n",
       " 'Dirk',\n",
       " 'München',\n",
       " 'Game of',\n",
       " 'Game of Thrones',\n",
       " 'Game',\n",
       " 'mit dem',\n",
       " 'Frankfurter',\n",
       " 'in den',\n",
       " 'Amerika',\n",
       " 'Theresa',\n",
       " 'Israel',\n",
       " 'Deutsche',\n",
       " 'London',\n",
       " 'Verfolgen',\n",
       " 'Bild',\n",
       " 'große',\n",
       " 'mit der',\n",
       " 'an der',\n",
       " 'britische',\n",
       " 'Wahl',\n",
       " 'Mittwoch',\n",
       " 'Prozent',\n",
       " 'Eintracht',\n",
       " 'nach dem',\n",
       " 'Partei',\n",
       " 'gewinnt',\n",
       " 'Interview',\n",
       " 'Millionen',\n",
       " 'April',\n",
       " 'droht',\n",
       " 'vergangenen',\n",
       " 'China',\n",
       " 'alte',\n",
       " 'Europa',\n",
       " 'Woche',\n",
       " 'stellt',\n",
       " 'auf die',\n",
       " 'in die',\n",
       " 'Formel',\n",
       " 'Kampf',\n",
       " 'Netanjahu',\n",
       " 'und die',\n",
       " 'im Liveticker',\n",
       " 'Angela',\n",
       " 'Europawahl',\n",
       " 'Frankfurt',\n",
       " 'Champions League',\n",
       " 'Geld',\n",
       " 'Vettel',\n",
       " 'Woods',\n",
       " 'ist ein',\n",
       " 'mit einem',\n",
       " 'auf der',\n",
       " 'deutlich',\n",
       " 'Kirche',\n",
       " 'Premierministerin',\n",
       " 'Tiger',\n",
       " 'Regierung',\n",
       " 'Vater',\n",
       " 'auf dem',\n",
       " 'Staaten',\n",
       " 'Feuer',\n",
       " 'Briten',\n",
       " 'nächsten',\n",
       " 'Stadt',\n",
       " 'Manchester',\n",
       " 'Unternehmen',\n",
       " 'März',\n",
       " 'Sebastian',\n",
       " 'aus der',\n",
       " 'Blick',\n",
       " 'Wiederaufbau',\n",
       " 'Rennen',\n",
       " 'Markus',\n",
       " 'Probleme',\n",
       " 'Vereinigten',\n",
       " 'Gericht',\n",
       " 'Opfer',\n",
       " 'Loch',\n",
       " 'Kritik',\n",
       " 'Flughafen',\n",
       " 'Dortmund',\n",
       " 'Sieg',\n",
       " 'amerikanischen',\n",
       " 'Leben',\n",
       " 'sorgt',\n",
       " 'Anfang',\n",
       " 'Debatte',\n",
       " 'Ministerpräsident',\n",
       " 'Land',\n",
       " 'hält',\n",
       " 'Köln',\n",
       " 'Platz',\n",
       " 'Druck',\n",
       " 'auf den',\n",
       " 'Pariser',\n",
       " 'Bank',\n",
       " 'Staffel',\n",
       " 'Wochen',\n",
       " 'Barcelona',\n",
       " 'trifft',\n",
       " 'Trumps',\n",
       " '1000',\n",
       " 'amerikanische',\n",
       " 'verliert',\n",
       " 'Julian Assange',\n",
       " 'Stuttgart',\n",
       " 'Polizisten',\n",
       " 'mehr als',\n",
       " 'Zahl',\n",
       " 'Berliner',\n",
       " 'Studie',\n",
       " 'Präsidenten',\n",
       " 'Macron',\n",
       " 'Lösung',\n",
       " 'Benjamin',\n",
       " 'Robert',\n",
       " 'Milliarden',\n",
       " 'Botschaft',\n",
       " 'Finale',\n",
       " 'um den',\n",
       " 'Dirk Nowitzki',\n",
       " 'Frage',\n",
       " 'zweiten',\n",
       " 'läuft',\n",
       " 'NotreDameKathedrale',\n",
       " 'führt',\n",
       " 'zahlen',\n",
       " 'Scheuer',\n",
       " 'erklärt',\n",
       " 'sich die',\n",
       " 'über die',\n",
       " 'Frauen',\n",
       " 'besten',\n",
       " 'Oktober',\n",
       " 'Bremen',\n",
       " 'Bundesliga im',\n",
       " 'Bundesliga im Liveticker',\n",
       " 'in einer',\n",
       " 'Tor',\n",
       " 'von der',\n",
       " 'Serie',\n",
       " 'hat die',\n",
       " 'legt',\n",
       " 'frühere',\n",
       " 'verdient',\n",
       " 'Kanzlerin',\n",
       " 'liegen',\n",
       " '2018',\n",
       " 'Duell',\n",
       " 'Augusta',\n",
       " 'Theresa May',\n",
       " 'nicht mehr',\n",
       " 'britischen',\n",
       " 'Mainz',\n",
       " 'erfolgreich',\n",
       " '21',\n",
       " 'Düsseldorf',\n",
       " 'Boeing',\n",
       " 'ist die',\n",
       " '20',\n",
       " 'stehen',\n",
       " 'Pressekonferenz',\n",
       " 'Internet',\n",
       " 'Russland',\n",
       " 'Tag',\n",
       " 'nahe',\n",
       " 'Thomas',\n",
       " 'und der',\n",
       " 'Donald Trump',\n",
       " 'Parlament',\n",
       " 'Altmaier',\n",
       " 'Familie',\n",
       " 'Grenze',\n",
       " 'Spieler',\n",
       " 'NBA',\n",
       " 'Hauptstadt',\n",
       " 'vor allem',\n",
       " 'um die',\n",
       " 'in Deutschland',\n",
       " 'Parlamentswahl',\n",
       " 'Jahres',\n",
       " 'beendet',\n",
       " 'aus dem',\n",
       " 'größte',\n",
       " 'Friedrich',\n",
       " 'Dienstag',\n",
       " 'ehemalige',\n",
       " 'bekommen',\n",
       " 'Haus',\n",
       " 'alten',\n",
       " 'Gefahr',\n",
       " 'an die',\n",
       " 'hohe',\n",
       " 'Spiele',\n",
       " 'hat sich',\n",
       " 'Max',\n",
       " 'Geschichte',\n",
       " 'Masters',\n",
       " 'Montag',\n",
       " 'Bundestag',\n",
       " 'Borussia',\n",
       " 'Instagram',\n",
       " 'Quartal',\n",
       " 'ist der',\n",
       " 'schwer',\n",
       " 'Street',\n",
       " 'Bericht',\n",
       " 'ist das',\n",
       " 'Zug',\n",
       " 'United',\n",
       " 'Posten',\n",
       " 'Schalke',\n",
       " 'Sudan',\n",
       " 'mit einer',\n",
       " 'Martin',\n",
       " 'Chance',\n",
       " 'Verfolgen Sie',\n",
       " 'hilft',\n",
       " 'Bundesregierung',\n",
       " 'Grünen',\n",
       " 'Kim',\n",
       " 'Roman',\n",
       " 'Karriere',\n",
       " 'Teil',\n",
       " 'gibt es',\n",
       " 'Auto',\n",
       " 'Hannover',\n",
       " 'Wall',\n",
       " 'spielt',\n",
       " 'Ermittlungen',\n",
       " 'Star',\n",
       " 'Istanbul',\n",
       " 'Münchner',\n",
       " 'Schwarzen',\n",
       " 'und das',\n",
       " 'alt',\n",
       " 'über den',\n",
       " 'Zukunft',\n",
       " 'Papst',\n",
       " 'Großbritannien',\n",
       " 'Staatsanwalt',\n",
       " 'Sie das',\n",
       " 'erstmals',\n",
       " 'lang',\n",
       " '50',\n",
       " 'Haft',\n",
       " 'Führung',\n",
       " 'verloren',\n",
       " 'Flammen',\n",
       " 'Streit',\n",
       " 'Sieger',\n",
       " 'Event',\n",
       " 'vor dem',\n",
       " 'Jahre alte',\n",
       " 'Gegner',\n",
       " '11',\n",
       " 'verlassen',\n",
       " 'Forscher',\n",
       " 'Dortmunder',\n",
       " 'Vorwürfe',\n",
       " 'Michael',\n",
       " 'politische',\n",
       " 'Saison',\n",
       " 'Donnerstag',\n",
       " 'Medien',\n",
       " 'Merz',\n",
       " 'Frankreich',\n",
       " 'gestiegen',\n",
       " 'Innenminister',\n",
       " 'Andreas',\n",
       " 'nicht nur',\n",
       " 'Freitag',\n",
       " 'Informationen',\n",
       " 'Diskussion',\n",
       " 'Liverpool',\n",
       " 'gefunden',\n",
       " 'Horizon',\n",
       " 'Abgang',\n",
       " 'Opposition',\n",
       " 'Lochs',\n",
       " 'leben',\n",
       " 'groß',\n",
       " 'zeigen',\n",
       " '15',\n",
       " 'gewinnen',\n",
       " 'Foto',\n",
       " 'getötet',\n",
       " 'Gantz',\n",
       " 'Test',\n",
       " 'BVB',\n",
       " 'Herausforderer',\n",
       " 'Anleger',\n",
       " 'Meister',\n",
       " 'scheint',\n",
       " 'Wirtschaft',\n",
       " 'Verfolgen Sie das',\n",
       " 'Gold',\n",
       " 'Niederlage',\n",
       " 'Staat',\n",
       " 'Migranten',\n",
       " 'Erfolg',\n",
       " 'Eltern',\n",
       " 'Algorithmus',\n",
       " 'Autos',\n",
       " 'Dollar',\n",
       " 'die Polizei',\n",
       " 'Uber',\n",
       " 'Finnland',\n",
       " 'Tagen',\n",
       " 'Ärger',\n",
       " 'City',\n",
       " 'September',\n",
       " 'ARD',\n",
       " 'der Welt',\n",
       " 'Reinhard',\n",
       " 'Tiger Woods',\n",
       " 'TVKritik',\n",
       " 'Spitze',\n",
       " 'NotreDameKathedrale in',\n",
       " 'in London',\n",
       " 'KrampKarrenbauer',\n",
       " 'Insel',\n",
       " 'Gastbeitrag',\n",
       " 'Besuch',\n",
       " 'Finanzminister',\n",
       " 'FAZ',\n",
       " 'Fans',\n",
       " 'Peter',\n",
       " 'Samstag',\n",
       " 'glücklich',\n",
       " 'Omar',\n",
       " 'Nielsen',\n",
       " 'Deutscher',\n",
       " 'größten',\n",
       " 'das Spiel',\n",
       " 'Union',\n",
       " 'dem Weg',\n",
       " 'Gladbach',\n",
       " 'WikileaksGründer',\n",
       " 'schlagen',\n",
       " 'Anschlag',\n",
       " 'offen',\n",
       " 'nach der',\n",
       " 'schön',\n",
       " 'laufen',\n",
       " 'Mitarbeiter',\n",
       " 'Netflix',\n",
       " 'Ziel',\n",
       " 'Hoffnungen',\n",
       " 'Schwangere',\n",
       " 'vorerst',\n",
       " 'Feuerwehr',\n",
       " 'französische',\n",
       " '40',\n",
       " 'Grund',\n",
       " 'erreicht',\n",
       " 'sind die',\n",
       " 'Wissenschaftler',\n",
       " 'die EU',\n",
       " 'Rolle',\n",
       " 'Sicht',\n",
       " 'Ajax',\n",
       " 'Folge',\n",
       " 'verletzt',\n",
       " 'Flugbereitschaft',\n",
       " 'Mick',\n",
       " 'verurteilt',\n",
       " 'Maschinen',\n",
       " 'versucht',\n",
       " 'Grand',\n",
       " 'festgenommen',\n",
       " 'hoffen',\n",
       " 'Folgen',\n",
       " 'mit den',\n",
       " 'Indonesien',\n",
       " 'Sonntag',\n",
       " 'heißt',\n",
       " '100',\n",
       " 'Luft',\n",
       " 'Täter',\n",
       " 'länger',\n",
       " 'Straßen',\n",
       " 'Amsterdam',\n",
       " 'verhaftet',\n",
       " 'verlässt',\n",
       " 'Event Horizon',\n",
       " 'Beginn',\n",
       " 'Start',\n",
       " 'bekommt',\n",
       " 'Richtung',\n",
       " 'schwere',\n",
       " 'Bundeswehr',\n",
       " 'Brand in',\n",
       " 'Zentrum',\n",
       " '2016',\n",
       " 'Flugzeug',\n",
       " 'Schwarzes',\n",
       " 'Museum',\n",
       " 'Sebastian Vettel',\n",
       " 'Tage',\n",
       " 'fest',\n",
       " 'Nachrichten',\n",
       " 'bei einem',\n",
       " 'bei einer',\n",
       " 'Fehler',\n",
       " 'Premierministerin Theresa',\n",
       " 'Regierungschefs',\n",
       " 'ist nicht',\n",
       " 'Kunst',\n",
       " 'Unbekannte',\n",
       " 'Lufthansa',\n",
       " 'Seehofer',\n",
       " 'New',\n",
       " 'Umfrage',\n",
       " 'Sozialdemokraten',\n",
       " 'Benedikt',\n",
       " 'Londoner',\n",
       " 'für einen',\n",
       " 'Sommer',\n",
       " 'sucht',\n",
       " 'verteidigt',\n",
       " 'Freiheit',\n",
       " 'Chinas',\n",
       " 'Hertha',\n",
       " 'Schüler',\n",
       " 'zuvor',\n",
       " 'will die',\n",
       " 'für das',\n",
       " 'zu den',\n",
       " 'Halbfinale',\n",
       " 'Ronaldo',\n",
       " 'Glück',\n",
       " 'derweil',\n",
       " 'Marco',\n",
       " 'holt',\n",
       " 'Schauspielerin',\n",
       " 'CDU',\n",
       " 'präsentiert',\n",
       " 'Telescope',\n",
       " 'Duisburg',\n",
       " 'Ferrari',\n",
       " 'dringend',\n",
       " 'Greta',\n",
       " 'Schwarzes Loch',\n",
       " 'Kind',\n",
       " 'Frankreichs',\n",
       " 'beste',\n",
       " 'und eine',\n",
       " 'diskutiert',\n",
       " '96',\n",
       " 'Verlängerung',\n",
       " 'retten',\n",
       " 'Verluste',\n",
       " 'Fristverlängerung',\n",
       " 'Schritt',\n",
       " 'verspricht',\n",
       " 'Börse',\n",
       " 'dritten',\n",
       " 'trotz',\n",
       " 'knapp',\n",
       " 'fährt',\n",
       " 'Generation',\n",
       " 'Mädchen',\n",
       " 'Schmidt',\n",
       " 'Hecking',\n",
       " 'Unterstützung',\n",
       " 'Kritiker',\n",
       " 'bringt',\n",
       " 'Blogs',\n",
       " 'fünften',\n",
       " 'Die britische',\n",
       " 'Mercedes',\n",
       " 'Ausstellung',\n",
       " 'Einsatz',\n",
       " 'Spiel im Liveticker',\n",
       " 'Hart',\n",
       " 'Jörg',\n",
       " 'richtig',\n",
       " '05',\n",
       " 'weltberühmten',\n",
       " 'St',\n",
       " 'Problem',\n",
       " 'Fußball',\n",
       " 'Eindruck',\n",
       " 'Frank',\n",
       " 'Hamilton',\n",
       " 'fahren',\n",
       " 'Trikot',\n",
       " 'hat ein',\n",
       " 'Rechtspopulisten',\n",
       " 'Demonstranten',\n",
       " 'BrexitAufschub',\n",
       " 'Chef',\n",
       " 'Wahlkampf',\n",
       " 'erwartet',\n",
       " 'Tochter',\n",
       " 'Mainzer',\n",
       " 'vorgestellt',\n",
       " 'ZDF',\n",
       " 'entdeckt',\n",
       " 'Maschine',\n",
       " 'Alexander',\n",
       " 'Klimaschutz',\n",
       " 'Thema',\n",
       " 'Topspiel',\n",
       " 'Dame',\n",
       " 'los',\n",
       " 'Kurs',\n",
       " 'Mörder',\n",
       " 'SPD',\n",
       " 'Aufstieg',\n",
       " 'verhindern',\n",
       " 'Kathedrale NotreDame',\n",
       " 'Torwart',\n",
       " 'Abschied',\n",
       " 'von einem',\n",
       " 'Brüssel',\n",
       " 'fair',\n",
       " 'nicht in',\n",
       " 'Manuel',\n",
       " 'Dieter',\n",
       " 'Schumacher',\n",
       " 'Thunberg',\n",
       " 'Tusk',\n",
       " 'Tatort',\n",
       " 'Forderungen',\n",
       " 'Fälle',\n",
       " 'Deutschlands',\n",
       " 'Tripolis',\n",
       " 'Gründe',\n",
       " 'im Interview',\n",
       " 'gegen die',\n",
       " 'Position',\n",
       " 'EZB',\n",
       " 'Schanghai',\n",
       " 'Buch',\n",
       " 'im ersten',\n",
       " 'Karriereende',\n",
       " 'Zahlen',\n",
       " 'Wiederaufbau von',\n",
       " 'Israels',\n",
       " 'bilden',\n",
       " 'hebt',\n",
       " 'Tore',\n",
       " 'In der',\n",
       " 'hofft',\n",
       " 'York',\n",
       " 'Assistent',\n",
       " 'von den',\n",
       " 'Augen',\n",
       " 'Die britische Premierministerin',\n",
       " 'Scholz',\n",
       " 'Kraft',\n",
       " 'in Berlin',\n",
       " 'Fridays',\n",
       " 'hart',\n",
       " 'übernimmt',\n",
       " 'Kosten',\n",
       " 'Netanjahus',\n",
       " 'und den',\n",
       " 'Future',\n",
       " 'ecuadorianischen',\n",
       " 'warten',\n",
       " 'wartet',\n",
       " 'Grindel',\n",
       " 'der EU',\n",
       " 'sich das',\n",
       " 'Hart aber',\n",
       " 'schweren',\n",
       " 'Gesetz',\n",
       " 'ändern',\n",
       " 'Jan',\n",
       " 'erklären',\n",
       " 'der Europawahl',\n",
       " 'BasketballStar',\n",
       " 'fehlt',\n",
       " 'wichtige',\n",
       " 'die Bayern',\n",
       " 'Februar',\n",
       " 'Gespräch',\n",
       " 'Vereinigten Staaten',\n",
       " 'April 2019',\n",
       " 'Großbrand',\n",
       " 'wappnet',\n",
       " 'Jack',\n",
       " 'Hart aber fair',\n",
       " 'gemeinsam',\n",
       " 'Indien',\n",
       " 'Heimatschutzministerin',\n",
       " 'Kampf um',\n",
       " 'am Mittwoch',\n",
       " 'Demokraten',\n",
       " '2020',\n",
       " 'zu sein',\n",
       " 'kurz',\n",
       " 'Libyen',\n",
       " 'gegen den',\n",
       " 'besondere',\n",
       " 'Intelligenz',\n",
       " 'Amerikaner',\n",
       " 'Entscheidung',\n",
       " 'Vergangenheit',\n",
       " 'treffen',\n",
       " 'Kommentar',\n",
       " 'Ergebnis',\n",
       " 'Produktion',\n",
       " 'Podcast',\n",
       " 'erreichen',\n",
       " 'Schatten',\n",
       " 'Nürnberg',\n",
       " 'Banken',\n",
       " 'wirft',\n",
       " 'gescheitert',\n",
       " 'fällt',\n",
       " 'Plasberg',\n",
       " 'Spiel im',\n",
       " 'Soldaten',\n",
       " 'meldet',\n",
       " 'bereit',\n",
       " 'komplett',\n",
       " 'VfB',\n",
       " 'Politiker',\n",
       " 'Leistung',\n",
       " 'Commerzbank',\n",
       " 'rechnet',\n",
       " 'stark',\n",
       " 'für eine',\n",
       " 'Politik',\n",
       " 'Wikileaks',\n",
       " 'Hamburg',\n",
       " 'de',\n",
       " 'Stevens',\n",
       " 'eine neue',\n",
       " '737',\n",
       " 'Loughlin',\n",
       " 'Wochenende',\n",
       " 'Hoffenheim',\n",
       " 'Co',\n",
       " 'auf das',\n",
       " 'Auftakt',\n",
       " 'Preis',\n",
       " 'das Land',\n",
       " 'Schwarze',\n",
       " 'links und',\n",
       " 'Hoffnung',\n",
       " 'Verkehrsminister',\n",
       " 'Regierungschef',\n",
       " 'kritisiert',\n",
       " '2014',\n",
       " 'zweites',\n",
       " 'italienischen',\n",
       " 'Zustand',\n",
       " 'Morgan',\n",
       " 'Rückkehr',\n",
       " 'Salah',\n",
       " 'App',\n",
       " 'aufgenommen',\n",
       " 'NotreDameKathedrale in Paris',\n",
       " '33',\n",
       " 'Jahre alt',\n",
       " 'Abstimmung',\n",
       " 'Sozialen',\n",
       " 'demonstrieren',\n",
       " 'Uli',\n",
       " 'gegen Augsburg',\n",
       " 'Erdogan',\n",
       " 'Vorschlag',\n",
       " 'Jongun',\n",
       " 'Amt',\n",
       " 'verdienen',\n",
       " 'Illner',\n",
       " 'Notenbank',\n",
       " 'auf dem Weg',\n",
       " 'Verteidigungsministerin',\n",
       " '30',\n",
       " 'Kurs auf',\n",
       " 'Gefängnis',\n",
       " 'Obama',\n",
       " 'Bottas',\n",
       " 'Ära',\n",
       " 'Annegret',\n",
       " 'Klopp',\n",
       " 'Ausmaß',\n",
       " 'Privatsphäre',\n",
       " '31',\n",
       " 'Monate',\n",
       " 'ist im',\n",
       " 'Ecuador',\n",
       " '26',\n",
       " 'Mai',\n",
       " 'Anne',\n",
       " 'Maybrit',\n",
       " 'EUStaaten',\n",
       " 'bis zum',\n",
       " 'Abend',\n",
       " 'Heidelberg',\n",
       " 'passiert',\n",
       " 'Monaten',\n",
       " 'Minuten',\n",
       " 'rückt',\n",
       " 'Messi',\n",
       " 'Nach dem',\n",
       " 'VW',\n",
       " 'in einem',\n",
       " 'Kontrolle',\n",
       " 'kehrt',\n",
       " 'bereitet',\n",
       " 'sich noch',\n",
       " 'nennt',\n",
       " 'absolviert',\n",
       " 'Airlines',\n",
       " 'Zinsen',\n",
       " 'Rose',\n",
       " 'Kandidaten',\n",
       " 'der Champions',\n",
       " 'Stuttgarter',\n",
       " 'und hat',\n",
       " 'Behörden',\n",
       " 'Plan',\n",
       " 'Sache',\n",
       " 'Horst',\n",
       " 'Triumph',\n",
       " 'der Deutschen',\n",
       " 'Champions League im',\n",
       " 'Pränataltests',\n",
       " 'Felix',\n",
       " 'Flucht',\n",
       " 'plant',\n",
       " 'geändert',\n",
       " 'Weltmeister',\n",
       " 'sprechen',\n",
       " 'drohen',\n",
       " 'den Wiederaufbau von',\n",
       " 'Journalisten',\n",
       " 'Raumfahrtprogramm',\n",
       " 'französischen',\n",
       " 'Pole',\n",
       " 'Reul',\n",
       " 'Wiener',\n",
       " 'Italien',\n",
       " 'vorgeworfen',\n",
       " 'Haushalt',\n",
       " 'Aufregung',\n",
       " 'überraschend',\n",
       " 'Lori',\n",
       " 'Benfica',\n",
       " 'Schluss',\n",
       " 'Event Horizon Telescope',\n",
       " 'Wurzeln',\n",
       " 'Afghanistan',\n",
       " 'Treffer',\n",
       " 'Kollegen',\n",
       " 'Enteignung',\n",
       " 'Referendum',\n",
       " 'Feuer in',\n",
       " 'Schadens',\n",
       " 'Leipzig',\n",
       " 'November',\n",
       " 'zeigt die',\n",
       " 'Meuthen',\n",
       " 'geboren',\n",
       " 'zeichnet',\n",
       " 'Bedingungen',\n",
       " 'sitzt',\n",
       " 'Galaxie',\n",
       " 'erwarten',\n",
       " 'in Paris',\n",
       " 'Kurdi',\n",
       " 'Europäische',\n",
       " 'Beobachtung',\n",
       " 'Episode',\n",
       " 'Vorgehen',\n",
       " 'Spektakel',\n",
       " 'Moçambique',\n",
       " 'EM',\n",
       " 'Manchester City',\n",
       " 'Golf',\n",
       " 'Mainz 05',\n",
       " 'Betrieb',\n",
       " 'fallen',\n",
       " 'Sie das Spiel',\n",
       " 'der NBA',\n",
       " 'ausgebrochen',\n",
       " 'Oliver',\n",
       " 'Proteste',\n",
       " 'der Wahl',\n",
       " 'Debakel',\n",
       " '10',\n",
       " 'gewonnen',\n",
       " 'La',\n",
       " 'JP',\n",
       " 'Es ist',\n",
       " 'sich in',\n",
       " 'feiert',\n",
       " 'Brücke',\n",
       " 'Feld',\n",
       " 'Wohnung',\n",
       " 'antreten',\n",
       " 'Masters in Augusta',\n",
       " 'Mehrheit',\n",
       " 'Europaparlament',\n",
       " 'Szene',\n",
       " '2017',\n",
       " 'Essay',\n",
       " 'Streitkräfte',\n",
       " 'Alba',\n",
       " 'Ideen',\n",
       " 'Angaben',\n",
       " 'Aktien',\n",
       " 'Koepka',\n",
       " 'verpasst',\n",
       " 'Ort',\n",
       " 'Ignoranz',\n",
       " 'Städten',\n",
       " 'Media',\n",
       " 'Alan Kurdi',\n",
       " 'Alan',\n",
       " 'Konzern',\n",
       " 'Schauspieler',\n",
       " 'Gesicht',\n",
       " 'Wende',\n",
       " 'im Sudan',\n",
       " 'Abstieg',\n",
       " 'der Zeit',\n",
       " 'aufwendig',\n",
       " 'Möglichkeiten',\n",
       " 'Mannschaft',\n",
       " 'Form',\n",
       " 'Mönchengladbach',\n",
       " 'und will',\n",
       " 'geplant',\n",
       " 'Beamte',\n",
       " 'Theo',\n",
       " 'selten',\n",
       " 'Namen',\n",
       " 'Stil',\n",
       " 'der Bundeswehr',\n",
       " 'Teams',\n",
       " 'Hürde',\n",
       " 'Markt',\n",
       " 'XVI',\n",
       " 'Arbeit',\n",
       " 'Asyl',\n",
       " '27',\n",
       " '1000 Rennen',\n",
       " 'Wahl in',\n",
       " 'Juni',\n",
       " 'ehemaligen',\n",
       " 'Europas',\n",
       " 'herrscht',\n",
       " 'auch in',\n",
       " '2015',\n",
       " 'gelingt',\n",
       " 'Zeiten',\n",
       " 'Frist',\n",
       " 'Van',\n",
       " 'FC Bayern',\n",
       " 'Freude',\n",
       " 'Preise',\n",
       " 'Sarah',\n",
       " 'Blick auf',\n",
       " 'Benjamin Netanjahu',\n",
       " 'Immobilien',\n",
       " 'das Ende',\n",
       " 'reist',\n",
       " 'Experten',\n",
       " 'Juve',\n",
       " 'Brasilien',\n",
       " 'Internationalen',\n",
       " 'teuer',\n",
       " 'Turin',\n",
       " 'will das',\n",
       " 'Grüne',\n",
       " 'Hoeneß',\n",
       " 'Blogs  FAZ',\n",
       " 'einer Pressekonferenz',\n",
       " 'Bluttests',\n",
       " 'weist',\n",
       " 'Uber nimmt',\n",
       " 'Lissabon',\n",
       " 'Untersuchung',\n",
       " 'katholischen',\n",
       " 'Fridays for Future',\n",
       " 'Fridays for',\n",
       " 'und ihr',\n",
       " 'wächst',\n",
       " 'Friedrich Merz',\n",
       " 'einen guten',\n",
       " 'wichtigste',\n",
       " 'souverän',\n",
       " 'wirkt',\n",
       " 'Wien',\n",
       " 'aber auch',\n",
       " 'Sendung',\n",
       " 'Urteil',\n",
       " 'beginnt',\n",
       " 'früheren',\n",
       " 'Ascacibar',\n",
       " 'muss sich',\n",
       " 'Angst',\n",
       " 'hat der',\n",
       " 'wissen',\n",
       " 'Schwarzen Lochs',\n",
       " 'Sachs',\n",
       " 'Angst vor',\n",
       " 'Hinspiel',\n",
       " 'reichen',\n",
       " 'Prix',\n",
       " 'den nächsten',\n",
       " 'Juventus',\n",
       " 'warnt',\n",
       " 'kleine',\n",
       " 'Fachleute',\n",
       " 'Netz',\n",
       " 'schaffen',\n",
       " 'Debatte um',\n",
       " 'großer',\n",
       " 'führen',\n",
       " 'gehört',\n",
       " 'schneller',\n",
       " 'Salvini',\n",
       " 'ist noch',\n",
       " 'Finnen',\n",
       " 'Kiel',\n",
       " 'Fahrverbote',\n",
       " 'Nils',\n",
       " 'Teaser',\n",
       " 'Runde',\n",
       " 'Alter',\n",
       " 'Team',\n",
       " 'liegt auch',\n",
       " 'im Kampf',\n",
       " 'Tausende',\n",
       " 'Kampagne',\n",
       " 'Strafe',\n",
       " 'es noch',\n",
       " 'schlechtes',\n",
       " 'wenn man',\n",
       " 'Wähler',\n",
       " 'auch die',\n",
       " 'im Netz',\n",
       " 'Teaser Bild',\n",
       " 'Marke',\n",
       " 'kritisch',\n",
       " 'sich auf',\n",
       " '67',\n",
       " 'Ermittlung',\n",
       " 'attraktiver']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = list(features_sort.index)\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_list = pd.DataFrame(feature_list)\n",
    "#feature_list.to_csv('/Users/torben/PycharmProjects/toolbox/feature/features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary={}\n",
    "\n",
    "for i in range(len(feature_list)):\n",
    "    dictionary[feature_list[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over 'politik' buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_buzzword = []\n",
    "\n",
    "for index, row in faz_pol.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    pol_buzzword.append(new_line)\n",
    "    \n",
    "    \n",
    "df_pol = pd.DataFrame(pol_buzzword, columns=feature_list)\n",
    "df_pol['goal_val'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over 'sport' buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_buzzword = []\n",
    "\n",
    "for index, row in faz_sport.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    sport_buzzword.append(new_line)\n",
    "\n",
    "df_sport = pd.DataFrame(sport_buzzword, columns=feature_list)\n",
    "df_sport['goal_val'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over 'wirtschaft' buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_buzzword = []\n",
    "\n",
    "for index, row in faz_eco.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    eco_buzzword.append(new_line)\n",
    "    \n",
    "df_eco = pd.DataFrame(eco_buzzword, columns=feature_list)\n",
    "df_eco['goal_val'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over remaining buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_buzzword = []\n",
    "\n",
    "for index, row in faz_rem.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    rem_buzzword.append(new_line)\n",
    "    \n",
    "df_rem = pd.DataFrame(rem_buzzword, columns=feature_list)\n",
    "df_rem['goal_val'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [df_pol, df_eco, df_sport, df_rem]\n",
    "train_data = pd.concat(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**saving the train data frames to a .csv file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathname: ../data_frames/train_data\n"
     ]
    }
   ],
   "source": [
    "name = 'train_data'\n",
    "\n",
    "path = \"../data_frames/\" + name\n",
    "print(\"Pathname:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAME FOR TEST DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_tables(category):\n",
    "    raw_article = []\n",
    "    if category is 'aktuell':\n",
    "        path = f\"../data/aktuell/\"\n",
    "    else:\n",
    "        path = f\"../data/{category}/\"\n",
    "        \n",
    "    all_files = glob.glob(path + '*.csv')\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        raw_article.append(df)\n",
    "    faz_article = pd.concat(raw_article, axis=0, ignore_index=True)\n",
    "    faz_article['label'] = category\n",
    "\n",
    "    return faz_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fram = []\n",
    "\n",
    "for key, value in category.items():\n",
    "    raw_test = build_test_tables(value)\n",
    "    fram.append(raw_test)\n",
    "    faz_test = pd.concat(fram, axis=0, ignore_index=True)\n",
    "    \n",
    "faz_test = faz_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_pol_t = faz_test[faz_test.label == 'politik']\n",
    "faz_sport_t = faz_test[faz_test.label == 'sport']\n",
    "faz_eco_t = faz_test[faz_test.label == 'wirtschaft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_test_2 = faz_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_test_2 = faz_test_2[faz_test_2.label != 'politik']\n",
    "faz_test_2 = faz_test_2[faz_test_2.label != 'sport']\n",
    "faz_test_2 = faz_test_2[faz_test_2.label != 'wirtschaft']\n",
    "faz_rem_t = faz_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pol_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_buzzword_t = []\n",
    "\n",
    "for index, row in faz_pol_t.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    pol_buzzword_t.append(new_line)\n",
    "    \n",
    "df_pol_t = pd.DataFrame(pol_buzzword_t, columns=feature_list)\n",
    "df_pol_t['goal_val'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sport_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_buzzword_t = []\n",
    "\n",
    "for index, row in faz_sport_t.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    sport_buzzword_t.append(new_line)\n",
    "    \n",
    "df_sport_t = pd.DataFrame(sport_buzzword_t, columns=feature_list)\n",
    "df_sport_t['goal_val'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eco_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_buzzword_t = []\n",
    "\n",
    "for index, row in faz_eco_t.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    eco_buzzword_t.append(new_line)\n",
    "    \n",
    "df_eco_t = pd.DataFrame(eco_buzzword_t, columns=feature_list)\n",
    "df_eco_t['goal_val'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rem_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_buzzword_t = []\n",
    "\n",
    "for index, row in faz_rem_t.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    rem_buzzword_t.append(new_line)\n",
    "    \n",
    "df_rem_t = pd.DataFrame(rem_buzzword_t, columns=feature_list)\n",
    "df_rem_t['goal_val'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tables = [df_pol_t, df_sport_t, df_eco_t, df_rem_t]\n",
    "top_test_data = pd.concat(test_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**saving the data frames to a .csv file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathname: ../data_frames/test_data\n"
     ]
    }
   ],
   "source": [
    "name = 'test_data'\n",
    "\n",
    "path = \"../data_frames/\" + name\n",
    "print(\"Pathname:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_test_data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
