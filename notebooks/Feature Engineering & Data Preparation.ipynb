{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files from data\n",
    "\n",
    "load all the articles from local storage (new_data & data) and prepare the tables for the subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The for-loop gathers all the .csv files within the data directory, concats and labels them and then returns a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = {\n",
    "    1: 'politik', 2: 'wirtschaft', 3: 'finanzen', 4: 'feuilleton', 5: 'sport', 6: 'gesellschaft', 7: 'stil', \n",
    "    8: 'technik-motor', 9: 'wissen', 10: 'reise', 11: 'beruf-chance'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tables(category):\n",
    "    raw_articles = []\n",
    "    if category is 'aktuell':\n",
    "        path = f\"../new_data/aktuell/\"\n",
    "    else:\n",
    "        path = f\"../new_data/{category}/\"\n",
    "        \n",
    "    all_files = glob.glob(path + '*.csv')\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        raw_articles.append(df)\n",
    "    faz_articles = pd.concat(raw_articles, axis=0, ignore_index=True)\n",
    "    faz_articles['label'] = category\n",
    "\n",
    "    return faz_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Generate Test and Train Data\n",
    "\n",
    "**This for-loop goes through the data frames built in the first step and then collects the words from each entry in a list.**\n",
    "\n",
    "## Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for key, value in category.items():\n",
    "    raw_faz = build_tables(value)\n",
    "    frames.append(raw_faz)\n",
    "    faz_train = pd.concat(frames, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_train = faz_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faz_train_seq = faz_train['detailed']\n",
    "#faz_train_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faz_train[faz_train['label'] == 'aktuell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>detailed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beruf-chance</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feuilleton</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finanzen</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gesellschaft</th>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politik</th>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reise</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stil</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technik-motor</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wirtschaft</th>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wissen</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               link  published  title  detailed\n",
       "label                                          \n",
       "beruf-chance     22         22     22        22\n",
       "feuilleton      128        128    128       128\n",
       "finanzen         84         84     84        84\n",
       "gesellschaft    157        157    157       157\n",
       "politik         292        292    292       292\n",
       "reise            12         12     12        12\n",
       "sport           268        268    268       268\n",
       "stil             33         33     33        33\n",
       "technik-motor    36         36     36        36\n",
       "wirtschaft      184        184    184       184\n",
       "wissen           51         51     51        51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_train.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train data in 'politik' and 'rest':\n",
    "\n",
    "This step is for the sake of labelling the subsequant data and to get an idea of the data distribution (**'Politics' make up about 17% of the train data**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_train.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_pol = faz_train[faz_train.label == 'politik']\n",
    "faz_sport = faz_train[faz_train.label == 'sport']\n",
    "faz_eco = faz_train[faz_train.label == 'wirtschaft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_train_2 = faz_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_train_2 = faz_train_2[faz_train_2.label != 'politik']\n",
    "faz_train_2 = faz_train_2[faz_train_2.label != 'sport']\n",
    "faz_train_2 = faz_train_2[faz_train_2.label != 'wirtschaft']\n",
    "faz_rem = faz_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_rem.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>detailed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beruf-chance</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feuilleton</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finanzen</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gesellschaft</th>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reise</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stil</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technik-motor</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wissen</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               link  published  title  detailed\n",
       "label                                          \n",
       "beruf-chance     22         22     22        22\n",
       "feuilleton      128        128    128       128\n",
       "finanzen         84         84     84        84\n",
       "gesellschaft    157        157    157       157\n",
       "reise            12         12     12        12\n",
       "stil             33         33     33        33\n",
       "technik-motor    36         36     36        36\n",
       "wissen           51         51     51        51"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_rem.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build feature word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgx_singles = re.compile(\"([\\w][\\w']*[\\w])\")\n",
    "rgx_doubles = re.compile(\"([\\w][\\w']*[\\w] +[\\w][\\w']*[\\w])\")\n",
    "rgx_triples = re.compile(\"([\\w][\\w']*[\\w] +[\\w][\\w']*[\\w] +[\\w][\\w']*[\\w])\")\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for index, row in faz_train.iterrows():\n",
    "    line = row['detailed'].translate(translator)\n",
    "    words += rgx_singles.findall(line)\n",
    "    words += rgx_doubles.findall(line)\n",
    "    words += rgx_triples.findall(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = pd.DataFrame(words, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for index, row in faz_train.iterrows():\n",
    "    line = row['title'].translate(translator)\n",
    "    titles += rgx_singles.findall(line)\n",
    "    titles += rgx_doubles.findall(line)\n",
    "    titles += rgx_triples.findall(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = pd.DataFrame(titles, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped = [word_list, title_list]\n",
    "merged = pd.concat(scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all words that are in the stopword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = merged['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = pd.read_csv('/Users/torben/PycharmProjects/toolbox/stopwords/stopwords.csv', index_col=None, header=0)\n",
    "stopwordupper = pd.read_csv('/Users/torben/PycharmProjects/toolbox/stopwords/stopwordsupper.csv', index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopword['words'].tolist()\n",
    "stopwordsupper = stopwordupper['words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [word for word in merged_list if word not in stopwords]\n",
    "fin_feat_list = [word for word in feature_list if word not in stopwordsupper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(fin_feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.groupby('words').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.sort_values('count', ascending=False)\n",
    "features_sort = features.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jahre',\n",
       " 'in der',\n",
       " 'Trump',\n",
       " 'Jahren',\n",
       " 'Liveticker',\n",
       " 'Zeit',\n",
       " 'Trainer',\n",
       " 'Assange',\n",
       " 'deutschen',\n",
       " 'Berlin',\n",
       " 'Welt',\n",
       " 'EU',\n",
       " 'Deutschland',\n",
       " 'Menschen',\n",
       " 'Brexit',\n",
       " 'für die',\n",
       " 'Julian',\n",
       " 'May',\n",
       " 'deutsche',\n",
       " 'zeigt',\n",
       " 'Präsident',\n",
       " 'Nowitzki',\n",
       " 'Bayern',\n",
       " 'Donald',\n",
       " 'Spiel',\n",
       " 'Jahr',\n",
       " 'Polizei',\n",
       " 'Bundesliga',\n",
       " 'offenbar',\n",
       " 'League',\n",
       " 'Augsburg',\n",
       " 'Dirk',\n",
       " 'AfD',\n",
       " 'Kinder',\n",
       " 'lässt',\n",
       " 'großen',\n",
       " 'of',\n",
       " 'FC',\n",
       " 'Game',\n",
       " 'München',\n",
       " 'Thrones',\n",
       " 'Theresa',\n",
       " 'Game of',\n",
       " 'Game of Thrones',\n",
       " 'spricht',\n",
       " 'britische',\n",
       " 'große',\n",
       " 'Eintracht',\n",
       " 'London',\n",
       " 'mit dem',\n",
       " 'Champions',\n",
       " 'Bild',\n",
       " 'Amerika',\n",
       " 'Europa',\n",
       " 'an der',\n",
       " 'lange',\n",
       " 'Frankfurter',\n",
       " 'China',\n",
       " 'Wahl',\n",
       " 'Deutsche',\n",
       " 'Deutschen',\n",
       " 'Euro',\n",
       " 'Israel',\n",
       " 'Verfolgen',\n",
       " 'bei der',\n",
       " 'gewinnt',\n",
       " 'Merkel',\n",
       " 'mit der',\n",
       " 'Netanjahu',\n",
       " 'Premierministerin',\n",
       " 'Mittwoch',\n",
       " 'stellt',\n",
       " 'mit einem',\n",
       " 'Kampf',\n",
       " 'auf dem',\n",
       " 'in die',\n",
       " 'Woche',\n",
       " 'Partei',\n",
       " 'April',\n",
       " 'Regierung',\n",
       " 'Frankfurt',\n",
       " 'Unternehmen',\n",
       " 'auf die',\n",
       " 'im Liveticker',\n",
       " 'droht',\n",
       " 'März',\n",
       " 'Interview',\n",
       " 'nach dem',\n",
       " 'Rennen',\n",
       " 'alte',\n",
       " 'Formel',\n",
       " 'Dortmund',\n",
       " 'nächsten',\n",
       " 'Geld',\n",
       " 'deutlich',\n",
       " 'und die',\n",
       " 'vergangenen',\n",
       " 'auf der',\n",
       " 'Debatte',\n",
       " 'Millionen',\n",
       " 'sorgt',\n",
       " 'Vater',\n",
       " 'Vettel',\n",
       " 'Briten',\n",
       " 'Opfer',\n",
       " 'Druck',\n",
       " 'Loch',\n",
       " '1000',\n",
       " 'amerikanische',\n",
       " 'Julian Assange',\n",
       " 'Trumps',\n",
       " 'Vereinigten',\n",
       " 'Platz',\n",
       " 'hält',\n",
       " 'Staffel',\n",
       " 'für den',\n",
       " 'Markus',\n",
       " 'Champions League',\n",
       " 'ist ein',\n",
       " 'Anfang',\n",
       " 'Sebastian',\n",
       " 'Gericht',\n",
       " 'Stuttgart',\n",
       " 'Sieg',\n",
       " 'Angela',\n",
       " 'Paris',\n",
       " 'Staaten',\n",
       " 'Woods',\n",
       " 'Benjamin',\n",
       " 'verliert',\n",
       " 'Oktober',\n",
       " 'in den',\n",
       " 'Stadt',\n",
       " '2019',\n",
       " 'Botschaft',\n",
       " 'Ministerpräsident',\n",
       " 'Dirk Nowitzki',\n",
       " 'läuft',\n",
       " 'Tiger',\n",
       " 'Bank',\n",
       " 'auf den',\n",
       " 'besten',\n",
       " 'Lösung',\n",
       " 'Bremen',\n",
       " 'britischen',\n",
       " 'Köln',\n",
       " 'Land',\n",
       " 'Probleme',\n",
       " 'Leben',\n",
       " 'Theresa May',\n",
       " '20',\n",
       " 'Boeing',\n",
       " 'frühere',\n",
       " 'führt',\n",
       " 'sich die',\n",
       " 'von der',\n",
       " 'aus der',\n",
       " 'Kritik',\n",
       " 'amerikanischen',\n",
       " 'Milliarden',\n",
       " 'NBA',\n",
       " 'Prozent',\n",
       " 'Studie',\n",
       " 'nahe',\n",
       " 'Bundesliga im',\n",
       " 'Bundesliga im Liveticker',\n",
       " 'Tor',\n",
       " 'Pressekonferenz',\n",
       " 'Friedrich',\n",
       " 'beendet',\n",
       " 'Serie',\n",
       " 'erfolgreich',\n",
       " 'Altmaier',\n",
       " 'in einer',\n",
       " 'Tag',\n",
       " 'Mainz',\n",
       " 'Präsidenten',\n",
       " 'Europawahl',\n",
       " 'Street',\n",
       " 'Thomas',\n",
       " 'größte',\n",
       " 'Instagram',\n",
       " 'Borussia',\n",
       " 'Sudan',\n",
       " 'zahlen',\n",
       " 'Manchester',\n",
       " 'Augusta',\n",
       " 'Zahl',\n",
       " 'Jahres',\n",
       " 'mehr als',\n",
       " 'Hauptstadt',\n",
       " 'trifft',\n",
       " 'um den',\n",
       " 'aus dem',\n",
       " 'Schalke',\n",
       " 'alten',\n",
       " 'Grenze',\n",
       " 'Familie',\n",
       " 'Geschichte',\n",
       " 'Hannover',\n",
       " 'Düsseldorf',\n",
       " 'Wochen',\n",
       " 'liegen',\n",
       " 'bekommen',\n",
       " 'Zug',\n",
       " 'Blick',\n",
       " 'Karriere',\n",
       " 'Wall',\n",
       " 'Frauen',\n",
       " 'Finale',\n",
       " 'Duell',\n",
       " 'Max',\n",
       " 'Martin',\n",
       " 'Zukunft',\n",
       " 'Robert',\n",
       " 'Berliner',\n",
       " 'hat sich',\n",
       " '2018',\n",
       " 'Dortmunder',\n",
       " 'Chance',\n",
       " 'Parlamentswahl',\n",
       " 'Spieler',\n",
       " 'Gegner',\n",
       " 'über den',\n",
       " 'Bundestag',\n",
       " 'in Deutschland',\n",
       " 'stehen',\n",
       " 'mit einer',\n",
       " 'Flughafen',\n",
       " 'und der',\n",
       " 'erklärt',\n",
       " 'Verfolgen Sie',\n",
       " 'Sieger',\n",
       " 'Posten',\n",
       " 'um die',\n",
       " 'zweiten',\n",
       " 'ist die',\n",
       " '50',\n",
       " 'Forscher',\n",
       " 'Haft',\n",
       " 'Donald Trump',\n",
       " 'Merz',\n",
       " 'über die',\n",
       " 'Liverpool',\n",
       " 'Masters',\n",
       " 'Schwarzen',\n",
       " '21',\n",
       " 'Michael',\n",
       " 'City',\n",
       " 'Kanzlerin',\n",
       " 'Finnland',\n",
       " 'Gantz',\n",
       " 'ehemalige',\n",
       " 'Abgang',\n",
       " 'ist das',\n",
       " 'BVB',\n",
       " 'Migranten',\n",
       " 'Niederlage',\n",
       " 'Scheuer',\n",
       " 'Tagen',\n",
       " 'Star',\n",
       " 'Russland',\n",
       " 'und das',\n",
       " 'Medien',\n",
       " 'Opposition',\n",
       " 'Andreas',\n",
       " 'hat die',\n",
       " 'Führung',\n",
       " 'Parlament',\n",
       " 'Freitag',\n",
       " 'Uber',\n",
       " 'Verfolgen Sie das',\n",
       " 'Bericht',\n",
       " 'Innenminister',\n",
       " 'Samstag',\n",
       " 'das Spiel',\n",
       " 'Mick',\n",
       " 'erstmals',\n",
       " 'glücklich',\n",
       " 'vor allem',\n",
       " 'in London',\n",
       " 'Reinhard',\n",
       " 'dem Weg',\n",
       " 'Istanbul',\n",
       " 'Sicht',\n",
       " 'Internet',\n",
       " 'Gladbach',\n",
       " 'Nielsen',\n",
       " 'Event',\n",
       " 'Papst',\n",
       " 'ist der',\n",
       " 'Gefahr',\n",
       " 'Meister',\n",
       " 'Grünen',\n",
       " 'hilft',\n",
       " 'Peter',\n",
       " 'Großbritannien',\n",
       " 'Sie das',\n",
       " 'WikileaksGründer',\n",
       " 'Roman',\n",
       " 'leben',\n",
       " 'hohe',\n",
       " 'an die',\n",
       " 'gefunden',\n",
       " 'Grand',\n",
       " 'Schwangere',\n",
       " 'Barcelona',\n",
       " 'Staatsanwalt',\n",
       " 'sind die',\n",
       " 'gibt es',\n",
       " 'gewinnen',\n",
       " 'Anschlag',\n",
       " 'die EU',\n",
       " 'Mitarbeiter',\n",
       " 'Montag',\n",
       " 'Frage',\n",
       " 'Kim',\n",
       " 'Anleger',\n",
       " 'schwer',\n",
       " 'vorerst',\n",
       " 'verlassen',\n",
       " 'Dollar',\n",
       " 'Unbekannte',\n",
       " 'Straßen',\n",
       " 'nicht nur',\n",
       " 'Insel',\n",
       " 'zeigen',\n",
       " 'Kunst',\n",
       " 'verletzt',\n",
       " 'der Welt',\n",
       " 'Horizon',\n",
       " 'Donnerstag',\n",
       " 'Lochs',\n",
       " 'will die',\n",
       " 'Ärger',\n",
       " 'scheint',\n",
       " 'Premierministerin Theresa',\n",
       " 'legt',\n",
       " 'versucht',\n",
       " 'verteidigt',\n",
       " 'Fans',\n",
       " 'Vorwürfe',\n",
       " 'Beginn',\n",
       " 'sucht',\n",
       " 'Jahre alte',\n",
       " 'Umfrage',\n",
       " 'heißt',\n",
       " 'politische',\n",
       " 'Deutscher',\n",
       " 'Spiele',\n",
       " 'mit den',\n",
       " 'Sonntag',\n",
       " 'Münchner',\n",
       " 'offen',\n",
       " '2016',\n",
       " 'Fehler',\n",
       " 'Frankreich',\n",
       " 'Schüler',\n",
       " 'Marco',\n",
       " 'CDU',\n",
       " 'Benedikt',\n",
       " 'verlässt',\n",
       " 'Schauspielerin',\n",
       " 'groß',\n",
       " 'Regierungschefs',\n",
       " 'Sozialdemokraten',\n",
       " 'Autos',\n",
       " 'verhaftet',\n",
       " 'getötet',\n",
       " 'Flugzeug',\n",
       " 'bei einer',\n",
       " 'Diskussion',\n",
       " 'Herausforderer',\n",
       " 'Algorithmus',\n",
       " 'EZB',\n",
       " 'Tusk',\n",
       " 'Hamilton',\n",
       " 'gestiegen',\n",
       " 'Schumacher',\n",
       " 'Mainzer',\n",
       " 'Karriereende',\n",
       " 'Fristverlängerung',\n",
       " 'Deutschlands',\n",
       " 'spielt',\n",
       " 'Saison',\n",
       " 'Fußball',\n",
       " '05',\n",
       " 'Dieter',\n",
       " 'Glück',\n",
       " 'nach der',\n",
       " 'knapp',\n",
       " 'Tatort',\n",
       " 'Wissenschaftler',\n",
       " 'zuvor',\n",
       " 'Die britische',\n",
       " 'alt',\n",
       " 'Folgen',\n",
       " 'Besuch',\n",
       " 'Rechtspopulisten',\n",
       " 'bei einem',\n",
       " 'Hecking',\n",
       " 'Börse',\n",
       " 'schwere',\n",
       " 'Fälle',\n",
       " 'Haus',\n",
       " 'Richtung',\n",
       " 'Mörder',\n",
       " 'Gastbeitrag',\n",
       " 'Erfolg',\n",
       " 'holt',\n",
       " 'Londoner',\n",
       " 'Trikot',\n",
       " 'derweil',\n",
       " 'BrexitAufschub',\n",
       " 'Position',\n",
       " 'Forderungen',\n",
       " 'Foto',\n",
       " 'Duisburg',\n",
       " 'Ziel',\n",
       " 'diskutiert',\n",
       " 'die Polizei',\n",
       " 'Freiheit',\n",
       " 'Ausstellung',\n",
       " 'Wirtschaft',\n",
       " 'TVKritik',\n",
       " 'Omar',\n",
       " 'erwartet',\n",
       " 'Alexander',\n",
       " 'Mercedes',\n",
       " 'Verlängerung',\n",
       " 'für einen',\n",
       " 'Tripolis',\n",
       " 'Schmidt',\n",
       " 'Polizisten',\n",
       " 'Spiel im Liveticker',\n",
       " 'Demonstranten',\n",
       " 'Chef',\n",
       " 'Bundesregierung',\n",
       " 'Soldaten',\n",
       " 'Auto',\n",
       " '96',\n",
       " 'vorgestellt',\n",
       " 'die Bayern',\n",
       " 'Chinas',\n",
       " 'Netflix',\n",
       " 'St',\n",
       " 'Union',\n",
       " 'ecuadorianischen',\n",
       " 'gegen den',\n",
       " 'Spitze',\n",
       " 'Grindel',\n",
       " 'retten',\n",
       " 'Streit',\n",
       " 'Banken',\n",
       " 'Netanjahus',\n",
       " 'Intelligenz',\n",
       " 'In der',\n",
       " 'richtig',\n",
       " 'von einem',\n",
       " 'Assistent',\n",
       " 'Future',\n",
       " 'Mädchen',\n",
       " 'hebt',\n",
       " 'Museum',\n",
       " 'BasketballStar',\n",
       " 'Brüssel',\n",
       " 'nicht in',\n",
       " 'Die britische Premierministerin',\n",
       " 'Event Horizon',\n",
       " 'und eine',\n",
       " 'entdeckt',\n",
       " 'bekommt',\n",
       " 'Zentrum',\n",
       " 'für das',\n",
       " 'Manuel',\n",
       " 'Halbfinale',\n",
       " 'schweren',\n",
       " 'Täter',\n",
       " 'Telescope',\n",
       " 'Kraft',\n",
       " 'Leistung',\n",
       " 'Ermittlungen',\n",
       " 'beste',\n",
       " 'stark',\n",
       " 'größten',\n",
       " 'Schwarzes',\n",
       " 'September',\n",
       " 'Macron',\n",
       " 'Kurs',\n",
       " 'fahren',\n",
       " 'Tochter',\n",
       " 'Kosten',\n",
       " 'Teil',\n",
       " 'verhindern',\n",
       " 'verurteilt',\n",
       " 'Seehofer',\n",
       " 'Ergebnis',\n",
       " 'Schritt',\n",
       " 'Commerzbank',\n",
       " 'fährt',\n",
       " 'bilden',\n",
       " 'treffen',\n",
       " 'schön',\n",
       " 'für eine',\n",
       " 'Entscheidung',\n",
       " 'Test',\n",
       " 'der EU',\n",
       " 'Demokraten',\n",
       " 'Politik',\n",
       " 'Grund',\n",
       " 'Kommentar',\n",
       " 'fest',\n",
       " 'Heimatschutzministerin',\n",
       " 'Produktion',\n",
       " 'Israels',\n",
       " 'verloren',\n",
       " 'Tage',\n",
       " 'Fridays',\n",
       " 'Aufstieg',\n",
       " 'Kritiker',\n",
       " 'VfB',\n",
       " 'Lori',\n",
       " 'Auftakt',\n",
       " 'auf dem Weg',\n",
       " 'vorgeworfen',\n",
       " 'Flucht',\n",
       " 'wichtige',\n",
       " 'Eltern',\n",
       " 'Felix',\n",
       " 'Schwarzes Loch',\n",
       " 'dritten',\n",
       " 'Triumph',\n",
       " '100',\n",
       " 'Staat',\n",
       " 'präsentiert',\n",
       " 'Augen',\n",
       " 'Weltmeister',\n",
       " 'nicht mehr',\n",
       " 'Tore',\n",
       " 'Ferrari',\n",
       " 'Ära',\n",
       " 'gegen Augsburg',\n",
       " 'EUStaaten',\n",
       " 'bringt',\n",
       " 'Gespräch',\n",
       " 'Morgan',\n",
       " 'Anne',\n",
       " 'Monaten',\n",
       " 'Pränataltests',\n",
       " 'Ecuador',\n",
       " 'Stevens',\n",
       " 'italienischen',\n",
       " 'sich noch',\n",
       " 'Raumfahrtprogramm',\n",
       " 'Minuten',\n",
       " 'Gesetz',\n",
       " '2020',\n",
       " 'Schatten',\n",
       " 'Kurs auf',\n",
       " 'Rose',\n",
       " 'Verluste',\n",
       " 'Sache',\n",
       " 'Illner',\n",
       " 'Behörden',\n",
       " '737',\n",
       " 'Wikileaks',\n",
       " 'Benfica',\n",
       " 'wartet',\n",
       " 'Verkehrsminister',\n",
       " 'Pole',\n",
       " 'Loughlin',\n",
       " 'Jörg',\n",
       " 'Abschied',\n",
       " 'hat ein',\n",
       " 'Sebastian Vettel',\n",
       " '11',\n",
       " 'rückt',\n",
       " 'Hoffenheim',\n",
       " 'VW',\n",
       " 'Amt',\n",
       " '40',\n",
       " 'Klopp',\n",
       " 'fällt',\n",
       " 'Reul',\n",
       " 'länger',\n",
       " 'Afghanistan',\n",
       " 'App',\n",
       " 'Folge',\n",
       " 'Eindruck',\n",
       " 'Horst',\n",
       " 'fünften',\n",
       " 'KrampKarrenbauer',\n",
       " 'demonstrieren',\n",
       " 'am Mittwoch',\n",
       " 'Bottas',\n",
       " 'Maybrit',\n",
       " '15',\n",
       " '33',\n",
       " 'Februar',\n",
       " '31',\n",
       " 'Luft',\n",
       " 'Nürnberg',\n",
       " 'hart',\n",
       " 'Salah',\n",
       " 'vor dem',\n",
       " 'Sommer',\n",
       " 'XVI',\n",
       " 'Abstimmung',\n",
       " 'Erdogan',\n",
       " 'auch in',\n",
       " 'Amerikaner',\n",
       " 'Gründe',\n",
       " 'Hinspiel',\n",
       " 'warten',\n",
       " 'Hertha',\n",
       " 'Wochenende',\n",
       " 'Prix',\n",
       " 'Hoffnungen',\n",
       " 'Hoffnung',\n",
       " 'bis zum',\n",
       " 'Beamte',\n",
       " 'souverän',\n",
       " 'Wohnung',\n",
       " 'Europaparlament',\n",
       " 'und den',\n",
       " 'Europäische',\n",
       " 'Gefängnis',\n",
       " 'Salvini',\n",
       " 'Enteignung',\n",
       " 'der NBA',\n",
       " 'Episode',\n",
       " 'meldet',\n",
       " 'warnt',\n",
       " 'Es ist',\n",
       " 'Abstieg',\n",
       " 'und ihr',\n",
       " 'auf das',\n",
       " 'wappnet',\n",
       " 'Zustand',\n",
       " 'bereit',\n",
       " 'im Sudan',\n",
       " 'Spiel im',\n",
       " 'und will',\n",
       " 'in Berlin',\n",
       " 'Alan',\n",
       " 'Zinsen',\n",
       " 'der Zeit',\n",
       " 'Namen',\n",
       " 'Referendum',\n",
       " 'Benjamin Netanjahu',\n",
       " 'Aktien',\n",
       " 'Hürde',\n",
       " 'Heidelberg',\n",
       " 'Alan Kurdi',\n",
       " 'Zeiten',\n",
       " 'ist noch',\n",
       " 'Bluttests',\n",
       " 'Gesicht',\n",
       " 'den nächsten',\n",
       " 'Brasilien',\n",
       " 'lang',\n",
       " 'Ignoranz',\n",
       " 'Regierungschef',\n",
       " 'Rolle',\n",
       " 'Spektakel',\n",
       " 'ist nicht',\n",
       " 'Mönchengladbach',\n",
       " 'links und',\n",
       " 'Preis',\n",
       " 'Einsatz',\n",
       " 'Schwarze',\n",
       " 'ist im',\n",
       " 'Rückkehr',\n",
       " 'Moçambique',\n",
       " 'Stuttgarter',\n",
       " 'Klimaschutz',\n",
       " '2014',\n",
       " 'erreicht',\n",
       " 'Indien',\n",
       " 'Frist',\n",
       " 'Konzern',\n",
       " 'ändern',\n",
       " 'FAZ',\n",
       " 'schneller',\n",
       " 'eine neue',\n",
       " 'Debakel',\n",
       " 'Debatte um',\n",
       " 'Manchester City',\n",
       " 'Uber nimmt',\n",
       " '30',\n",
       " 'Thema',\n",
       " 'Koepka',\n",
       " 'feiert',\n",
       " 'Mainz 05',\n",
       " 'Streitkräfte',\n",
       " 'gescheitert',\n",
       " 'Kampf um',\n",
       " 'Aufregung',\n",
       " 'erklären',\n",
       " 'plant',\n",
       " 'drohen',\n",
       " 'Treffer',\n",
       " 'Kurdi',\n",
       " 'hofft',\n",
       " 'zeigt die',\n",
       " 'Form',\n",
       " 'Asyl',\n",
       " 'zu den',\n",
       " 'La',\n",
       " 'Torwart',\n",
       " 'Teams',\n",
       " 'Internationalen',\n",
       " 'Indonesien',\n",
       " 'JP',\n",
       " 'Van',\n",
       " 'fehlt',\n",
       " 'Finnen',\n",
       " '27',\n",
       " 'Kirche',\n",
       " 'reichen',\n",
       " 'Friedrich Merz',\n",
       " '10',\n",
       " 'zu sein',\n",
       " 'Untersuchung',\n",
       " 'Libyen',\n",
       " 'Tiger Woods',\n",
       " 'Stil',\n",
       " 'Kiel',\n",
       " 'Theo',\n",
       " 'Wahl in',\n",
       " 'wirkt',\n",
       " 'wissen',\n",
       " 'einer Pressekonferenz',\n",
       " 'Lissabon',\n",
       " 'gegen die',\n",
       " 'herrscht',\n",
       " 'fallen',\n",
       " 'Topspiel',\n",
       " 'Mehrheit',\n",
       " 'Fridays for',\n",
       " 'will das',\n",
       " 'erwarten',\n",
       " 'Fridays for Future',\n",
       " 'ehemaligen',\n",
       " 'übernimmt',\n",
       " 'Brücke',\n",
       " 'Wende',\n",
       " 'rechnet',\n",
       " 'Maschine',\n",
       " 'Leipzig',\n",
       " 'einen guten',\n",
       " 'das Ende',\n",
       " 'israelische',\n",
       " 'großer',\n",
       " 'Schüsse',\n",
       " 'Lufthansa',\n",
       " 'Bilder',\n",
       " '26',\n",
       " 'BörseDer',\n",
       " 'Plattform',\n",
       " 'Podcast',\n",
       " 'Luftschadstoffe',\n",
       " 'verpasst',\n",
       " 'Brooks',\n",
       " 'Ajax',\n",
       " '44',\n",
       " 'Italien',\n",
       " 'ZDF',\n",
       " 'Bundestagsvizepräsidenten',\n",
       " 'der Champions',\n",
       " 'nun auch',\n",
       " 'Mary',\n",
       " 'muss sich',\n",
       " 'der Europawahl',\n",
       " 'Masters in Augusta',\n",
       " 'Sipilä',\n",
       " 'Fahrverbote',\n",
       " 'Szene',\n",
       " 'Wolfsburg',\n",
       " 'sorgen',\n",
       " 'November',\n",
       " 'Mannschaft',\n",
       " 'Vorschlag',\n",
       " 'Bedingungen',\n",
       " 'Herr',\n",
       " 'Airbus',\n",
       " 'steckt',\n",
       " 'Teaser Bild für',\n",
       " 'Teaser Bild',\n",
       " 'Teaser',\n",
       " 'Blogs',\n",
       " 'Generation',\n",
       " 'Vorgehen',\n",
       " 'ging',\n",
       " 'Bus',\n",
       " 'Herbert',\n",
       " 'den Vereinigten',\n",
       " 'Bahn',\n",
       " 'Tausende',\n",
       " 'in einem',\n",
       " 'Ermittlung',\n",
       " 'zweite',\n",
       " 'ETFs',\n",
       " 'Kovac',\n",
       " 'Urteil',\n",
       " '1000 Rennen',\n",
       " 'Greta',\n",
       " 'aufgenommen',\n",
       " 'Co',\n",
       " 'umstrittene',\n",
       " 'umstritten',\n",
       " 'Amsterdam',\n",
       " 'los',\n",
       " 'Kollegen',\n",
       " 'gelingt',\n",
       " 'Autohersteller',\n",
       " 'profitieren',\n",
       " 'kritisch',\n",
       " 'Fock',\n",
       " 'geplant',\n",
       " 'Tuchel',\n",
       " 'Ringen',\n",
       " 'Grenzen',\n",
       " 'SWR',\n",
       " 'Gorch',\n",
       " 'antreten',\n",
       " 'Kind',\n",
       " 'Runde',\n",
       " 'attraktiver',\n",
       " 'auch die',\n",
       " 'auch im',\n",
       " 'Unterstützung',\n",
       " 'Gorch Fock',\n",
       " 'Kirstjen',\n",
       " 'FlandernRundfahrt',\n",
       " 'Golf',\n",
       " 'liefern',\n",
       " 'überraschend',\n",
       " 'geboren',\n",
       " 'liegt auch',\n",
       " 'SPD',\n",
       " 'und hat',\n",
       " 'Cross',\n",
       " 'Schwarzen Lochs',\n",
       " 'Reform',\n",
       " 'Belfast',\n",
       " 'Ghosn',\n",
       " 'Psychiatrie',\n",
       " 'festgenommen',\n",
       " 'Anne Will',\n",
       " 'zweites',\n",
       " '2015',\n",
       " 'verdienen',\n",
       " 'verdient',\n",
       " '2017',\n",
       " 'Lehmann',\n",
       " 'absolviert',\n",
       " 'verfolgt',\n",
       " 'Erdbeben',\n",
       " 'Preise',\n",
       " 'Jongun',\n",
       " 'Thunberg',\n",
       " 'Enteignungen',\n",
       " 'Vereinigten Staaten',\n",
       " 'Benedikt XVI',\n",
       " 'Gündogan',\n",
       " 'politischen',\n",
       " 'Gullydeckel',\n",
       " 'Angst',\n",
       " 'Angst vor',\n",
       " 'schaffen',\n",
       " 'Schachmann',\n",
       " 'Razzien',\n",
       " 'geschlossene',\n",
       " 'Eigenheim',\n",
       " 'Kampagne',\n",
       " 'Schanghai',\n",
       " 'trotz',\n",
       " 'Besucher',\n",
       " 'schießen',\n",
       " 'Schauspieler',\n",
       " 'kehrt',\n",
       " 'Notfall',\n",
       " 'Elektroautos',\n",
       " 'im Interview',\n",
       " 'Start',\n",
       " 'siegt',\n",
       " 'Merkels',\n",
       " 'der letzten',\n",
       " 'Sorgen',\n",
       " 'nennt',\n",
       " 'Europas',\n",
       " '67',\n",
       " 'Brandenburg',\n",
       " 'in Israel',\n",
       " 'Experten',\n",
       " 'sie weiter',\n",
       " 'Städte',\n",
       " 'Nach dem',\n",
       " 'Strategie',\n",
       " 'Ministerin',\n",
       " 'sich das',\n",
       " 'Buch',\n",
       " 'Nerven',\n",
       " 'im Kampf',\n",
       " 'Assanges',\n",
       " 'wird die',\n",
       " 'der Wahl',\n",
       " 'Mutter',\n",
       " 'der Serie',\n",
       " 'selten',\n",
       " 'Städten',\n",
       " 'Nils',\n",
       " 'My',\n",
       " 'wenn man',\n",
       " 'sich in',\n",
       " 'New',\n",
       " 'Stunde',\n",
       " 'in China',\n",
       " 'Baum',\n",
       " 'Messi',\n",
       " 'Stellen',\n",
       " 'hinaus',\n",
       " 'Miller',\n",
       " 'Bund',\n",
       " 'hoffen',\n",
       " 'Netz',\n",
       " 'Event Horizon Telescope',\n",
       " 'Ideen',\n",
       " 'wichtigste',\n",
       " 'Die Finnen',\n",
       " 'Die Deutsche',\n",
       " 'im Netz',\n",
       " 'Militär',\n",
       " 'Branche',\n",
       " 'Stadion',\n",
       " 'BaskenlandRundfahrt',\n",
       " 'voraus',\n",
       " 'Nachrichten',\n",
       " 'Ball',\n",
       " 'der Polizei',\n",
       " 'FAZNET',\n",
       " 'Waigel',\n",
       " 'Assange in',\n",
       " 'sich für',\n",
       " 'Sophie',\n",
       " 'Informationen',\n",
       " 'bevorstehende',\n",
       " 'Haftar',\n",
       " 'schlagen',\n",
       " 'bis Ende',\n",
       " 'Bundesbank',\n",
       " 'Enttäuschung',\n",
       " 'Entwicklung',\n",
       " 'gesprochen',\n",
       " 'Ängste',\n",
       " 'schießt',\n",
       " 'Jürgen',\n",
       " 'Juve',\n",
       " 'Punkt',\n",
       " 'beteiligt',\n",
       " 'Künstliche',\n",
       " 'Schiff',\n",
       " 'Trainers',\n",
       " 'FC Bayern',\n",
       " 'des Jahres',\n",
       " 'als im',\n",
       " 'Quant',\n",
       " 'Radverkehr',\n",
       " 'Betrieb',\n",
       " 'kaufen',\n",
       " 'Investitionen',\n",
       " 'Eclipse',\n",
       " 'immer mehr',\n",
       " 'Spritpreise',\n",
       " 'Notenbank',\n",
       " 'Fraktion',\n",
       " 'nachhaltige Verkehrswende',\n",
       " 'gewarnt',\n",
       " 'Meuthen',\n",
       " 'nachhaltige',\n",
       " 'aber auch',\n",
       " 'Jubiläum',\n",
       " 'Verkehrswende',\n",
       " 'Jubel',\n",
       " 'Leopoldina',\n",
       " 'ehemaliger',\n",
       " 'Jovic',\n",
       " 'Lewandowski',\n",
       " 'Lewis',\n",
       " 'Leyen',\n",
       " 'EUAustritt',\n",
       " 'damals und ihr',\n",
       " 'Dienstag',\n",
       " 'Bauen',\n",
       " 'Problem',\n",
       " 'Sturm',\n",
       " 'Verhaftung',\n",
       " 'Le',\n",
       " 'Bettiol']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = list(features_sort.index)\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = pd.DataFrame(feature_list)\n",
    "feature_list.to_csv('/Users/torben/PycharmProjects/toolbox/feature/features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary={}\n",
    "\n",
    "for i in range(len(feature_list)):\n",
    "    dictionary[feature_list[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over 'politik' buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_buzzword = []\n",
    "\n",
    "for index, row in faz_pol.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    pol_buzzword.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol = pd.DataFrame(pol_buzzword, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol['goal_val'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over 'sport' buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_buzzword = []\n",
    "\n",
    "for index, row in faz_sport.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    sport_buzzword.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport = pd.DataFrame(sport_buzzword, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport['goal_val'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over 'wirtschaft' buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_buzzword = []\n",
    "\n",
    "for index, row in faz_eco.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    eco_buzzword.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eco = pd.DataFrame(eco_buzzword, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eco['goal_val'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over remaining buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_buzzword = []\n",
    "\n",
    "for index, row in faz_rem.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    rem_buzzword.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem = pd.DataFrame(rem_buzzword, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem['goal_val'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [df_pol, df_eco, df_sport, df_rem]\n",
    "train_data = pd.concat(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**saving the train data frames to a .csv file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathname: ../data_frames/train_data\n"
     ]
    }
   ],
   "source": [
    "name = 'train_data'\n",
    "\n",
    "path = \"../data_frames/\" + name\n",
    "print(\"Pathname:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAME FOR TEST DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_tables(category):\n",
    "    raw_article = []\n",
    "    if category is 'aktuell':\n",
    "        path = f\"../data/aktuell/\"\n",
    "    else:\n",
    "        path = f\"../data/{category}/\"\n",
    "        \n",
    "    all_files = glob.glob(path + '*.csv')\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        raw_article.append(df)\n",
    "    faz_article = pd.concat(raw_article, axis=0, ignore_index=True)\n",
    "    faz_article['label'] = category\n",
    "\n",
    "    return faz_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fram = []\n",
    "\n",
    "for key, value in category.items():\n",
    "    raw_test = build_test_tables(value)\n",
    "    fram.append(raw_test)\n",
    "    faz_test = pd.concat(fram, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_test = faz_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_pol_t = faz_test[faz_test.label == 'politik']\n",
    "faz_sport_t = faz_test[faz_test.label == 'sport']\n",
    "faz_eco_t = faz_test[faz_test.label == 'wirtschaft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_test_2 = faz_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_test_2 = faz_test_2[faz_test_2.label != 'politik']\n",
    "faz_test_2 = faz_test_2[faz_test_2.label != 'sport']\n",
    "faz_test_2 = faz_test_2[faz_test_2.label != 'wirtschaft']\n",
    "faz_rem_t = faz_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pol_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_buzzword_t = []\n",
    "\n",
    "for index, row in faz_pol_t.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    pol_buzzword_t.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_t = pd.DataFrame(pol_buzzword_t, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_t['goal_val'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sport_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_buzzword_t = []\n",
    "\n",
    "for index, row in faz_sport_t.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    sport_buzzword_t.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport_t = pd.DataFrame(sport_buzzword_t, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport_t['goal_val'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eco_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_buzzword_t = []\n",
    "\n",
    "for index, row in faz_eco_t.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    eco_buzzword_t.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eco_t = pd.DataFrame(eco_buzzword_t, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eco_t['goal_val'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rem_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_buzzword_t = []\n",
    "\n",
    "for index, row in faz_rem_t.iterrows():\n",
    "    new_line = np.zeros(1000)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    rem_buzzword_t.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_t = pd.DataFrame(rem_buzzword_t, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_t['goal_val'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tables = [df_pol_t, df_sport_t, df_eco_t, df_rem_t]\n",
    "top_test_data = pd.concat(test_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**saving the data frames to a .csv file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathname: ../data_frames/test_data\n"
     ]
    }
   ],
   "source": [
    "name = 'test_data'\n",
    "\n",
    "path = \"../data_frames/\" + name\n",
    "print(\"Pathname:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_test_data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
