{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files from data\n",
    "\n",
    "load all the articles from local storage (new_data & data) and prepare the tables for the subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The for-loop gathers all the .csv files within the data directory, concats and labels them and then returns a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = {\n",
    "    1: 'politik', 2: 'wirtschaft', 3: 'finanzen', 4: 'feuilleton', 5: 'sport', 6: 'gesellschaft', 7: 'stil', \n",
    "    8: 'technik-motor', 9: 'wissen', 10: 'reise', 11: 'beruf-chance', 12: 'aktuell'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tables(category):\n",
    "    raw_articles = []\n",
    "    if category is 'aktuell':\n",
    "        path = f\"../new_data/aktuell/\"\n",
    "    else:\n",
    "        path = f\"../new_data/{category}/\"\n",
    "        \n",
    "    all_files = glob.glob(path + '*.csv')\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        raw_articles.append(df)\n",
    "    faz_articles = pd.concat(raw_articles, axis=0, ignore_index=True)\n",
    "    faz_articles['label'] = category\n",
    "\n",
    "    return faz_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Generate Test and Train Data\n",
    "\n",
    "**This for-loop goes through the data frames built in the first step and then collects the words from each entry in a list.**\n",
    "\n",
    "## Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for key, value in category.items():\n",
    "    raw_faz = build_tables(value)\n",
    "    frames.append(raw_faz)\n",
    "    faz_train = pd.concat(frames, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_train = faz_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>detailed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aktuell</th>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beruf-chance</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feuilleton</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finanzen</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gesellschaft</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politik</th>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reise</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stil</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technik-motor</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wirtschaft</th>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wissen</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               link  published  title  detailed\n",
       "label                                          \n",
       "aktuell         748        748    748       748\n",
       "beruf-chance     21         21     21        21\n",
       "feuilleton      113        113    113       113\n",
       "finanzen         77         77     77        77\n",
       "gesellschaft    144        144    144       144\n",
       "politik         263        263    263       263\n",
       "reise            11         11     11        11\n",
       "sport           240        240    240       240\n",
       "stil             27         27     27        27\n",
       "technik-motor    33         33     33        33\n",
       "wirtschaft      162        162    162       162\n",
       "wissen           50         50     50        50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_train.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train data in 'politik' and 'rest':\n",
    "\n",
    "This step is for the sake of labelling the subsequant data and to get an idea of the data distribution (**'Politics' make up about 17% of the train data**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_train.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_pol = faz_train[faz_train.label == 'politik']\n",
    "faz_sport = faz_train[faz_train.label == 'sport']\n",
    "faz_eco = faz_train[faz_train.label == 'wirtschaft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_train_2 = faz_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_train_2 = faz_train_2[faz_train_2.label != 'politik']\n",
    "faz_train_2 = faz_train_2[faz_train_2.label != 'sport']\n",
    "faz_train_2 = faz_train_2[faz_train_2.label != 'wirtschaft']\n",
    "faz_rem = faz_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_rem.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>detailed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aktuell</th>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beruf-chance</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feuilleton</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finanzen</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gesellschaft</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reise</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stil</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technik-motor</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wissen</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               link  published  title  detailed\n",
       "label                                          \n",
       "aktuell         748        748    748       748\n",
       "beruf-chance     21         21     21        21\n",
       "feuilleton      113        113    113       113\n",
       "finanzen         77         77     77        77\n",
       "gesellschaft    144        144    144       144\n",
       "reise            11         11     11        11\n",
       "stil             27         27     27        27\n",
       "technik-motor    33         33     33        33\n",
       "wissen           50         50     50        50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faz_rem.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build feature word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgx_singles = re.compile(\"([\\w][\\w']*[\\w])\")\n",
    "rgx_doubles = re.compile(\"([\\w][\\w']*[\\w] +[\\w][\\w']*[\\w])\")\n",
    "rgx_triples = re.compile(\"([\\w][\\w']*[\\w] +[\\w][\\w']*[\\w] +[\\w][\\w']*[\\w])\")\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for index, row in faz_train.iterrows():\n",
    "    line = row['detailed'].translate(translator)\n",
    "    words += rgx_singles.findall(line)\n",
    "    words += rgx_doubles.findall(line)\n",
    "    words += rgx_triples.findall(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = pd.DataFrame(words, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for index, row in faz_train.iterrows():\n",
    "    line = row['title'].translate(translator)\n",
    "    titles += rgx_singles.findall(line)\n",
    "    titles += rgx_doubles.findall(line)\n",
    "    titles += rgx_triples.findall(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = pd.DataFrame(titles, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Randolph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>einer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pressekonferenz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oktober</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Regierungsmannschaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>des</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amerikanischen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Präsidenten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gibt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>den</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nächsten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Abgang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Heimatschutzministerin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nielsen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>geht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>auch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Direktor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>des</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Secret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24396</th>\n",
       "      <td>Limes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24397</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24398</th>\n",
       "      <td>der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24399</th>\n",
       "      <td>Wetterau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24400</th>\n",
       "      <td>Römischer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24401</th>\n",
       "      <td>Grenzwall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24402</th>\n",
       "      <td>wird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24403</th>\n",
       "      <td>sichtbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24404</th>\n",
       "      <td>Limes in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24405</th>\n",
       "      <td>der Wetterau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24406</th>\n",
       "      <td>Römischer Grenzwall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24407</th>\n",
       "      <td>wird sichtbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24408</th>\n",
       "      <td>Limes in der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24409</th>\n",
       "      <td>Wetterau Römischer Grenzwall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24410</th>\n",
       "      <td>Kritik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24411</th>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24412</th>\n",
       "      <td>Verkehrsminister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24413</th>\n",
       "      <td>Mehr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24414</th>\n",
       "      <td>als</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24415</th>\n",
       "      <td>Mio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24416</th>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24417</th>\n",
       "      <td>noch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24418</th>\n",
       "      <td>ohne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24419</th>\n",
       "      <td>SoftwareUpdate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24420</th>\n",
       "      <td>Kritik am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24421</th>\n",
       "      <td>Verkehrsminister Mehr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24422</th>\n",
       "      <td>Mio Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24423</th>\n",
       "      <td>noch ohne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24424</th>\n",
       "      <td>Kritik am Verkehrsminister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24425</th>\n",
       "      <td>Mio Diesel noch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153449 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               word\n",
       "0                          Randolph\n",
       "1                             Alles\n",
       "2                               auf\n",
       "3                             einer\n",
       "4                   Pressekonferenz\n",
       "5                                am\n",
       "6                                26\n",
       "7                           Oktober\n",
       "8                            2018In\n",
       "9                               der\n",
       "10             Regierungsmannschaft\n",
       "11                              des\n",
       "12                   amerikanischen\n",
       "13                      Präsidenten\n",
       "14                            Trump\n",
       "15                             gibt\n",
       "16                               es\n",
       "17                              den\n",
       "18                         nächsten\n",
       "19                           Abgang\n",
       "20                             Nach\n",
       "21           Heimatschutzministerin\n",
       "22                          Nielsen\n",
       "23                             geht\n",
       "24                              nun\n",
       "25                             auch\n",
       "26                              der\n",
       "27                         Direktor\n",
       "28                              des\n",
       "29                           Secret\n",
       "...                             ...\n",
       "24396                         Limes\n",
       "24397                            in\n",
       "24398                           der\n",
       "24399                      Wetterau\n",
       "24400                     Römischer\n",
       "24401                     Grenzwall\n",
       "24402                          wird\n",
       "24403                      sichtbar\n",
       "24404                      Limes in\n",
       "24405                  der Wetterau\n",
       "24406           Römischer Grenzwall\n",
       "24407                 wird sichtbar\n",
       "24408                  Limes in der\n",
       "24409  Wetterau Römischer Grenzwall\n",
       "24410                        Kritik\n",
       "24411                            am\n",
       "24412              Verkehrsminister\n",
       "24413                          Mehr\n",
       "24414                           als\n",
       "24415                           Mio\n",
       "24416                        Diesel\n",
       "24417                          noch\n",
       "24418                          ohne\n",
       "24419                SoftwareUpdate\n",
       "24420                     Kritik am\n",
       "24421         Verkehrsminister Mehr\n",
       "24422                    Mio Diesel\n",
       "24423                     noch ohne\n",
       "24424    Kritik am Verkehrsminister\n",
       "24425               Mio Diesel noch\n",
       "\n",
       "[153449 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped = [word_list, title_list]\n",
    "merged = pd.concat(scraped)\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all words that are in the stopword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = merged['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = pd.read_csv('/Users/torben/PycharmProjects/toolbox/stopwords/stopwords.csv', index_col=None, header=0)\n",
    "stopwordupper = pd.read_csv('/Users/torben/PycharmProjects/toolbox/stopwords/stopwordsupper.csv', index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopword['words'].tolist()\n",
    "stopwordsupper = stopwordupper['words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [word for word in merged_list if word not in stopwords]\n",
    "fin_feat_list = [word for word in feature_list if word not in stopwordsupper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(fin_feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.groupby('words').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.sort_values('count', ascending=False)\n",
    "features_sort = features.head(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jahre',\n",
       " 'in der',\n",
       " 'Liveticker',\n",
       " 'Trump',\n",
       " 'Zeit',\n",
       " 'EU',\n",
       " 'Nowitzki',\n",
       " 'Trainer',\n",
       " 'Assange',\n",
       " 'Jahren',\n",
       " 'Brexit',\n",
       " 'deutschen',\n",
       " 'Polizei',\n",
       " 'May',\n",
       " 'League',\n",
       " 'für die',\n",
       " 'Dirk',\n",
       " 'Deutschland',\n",
       " 'Berlin',\n",
       " 'zeigt',\n",
       " 'Donald',\n",
       " 'Julian',\n",
       " 'Menschen',\n",
       " 'Welt',\n",
       " 'deutsche',\n",
       " 'offenbar',\n",
       " 'Jahr',\n",
       " 'Spiel',\n",
       " 'AfD',\n",
       " 'Bundesliga',\n",
       " 'Präsident',\n",
       " 'Bayern',\n",
       " 'britische',\n",
       " 'Theresa',\n",
       " 'London',\n",
       " 'FC',\n",
       " 'Netanjahu',\n",
       " 'Champions',\n",
       " 'große',\n",
       " 'Europa',\n",
       " 'Merkel',\n",
       " 'Israel',\n",
       " 'Amerika',\n",
       " 'an der',\n",
       " 'Kinder',\n",
       " 'München',\n",
       " 'Eintracht',\n",
       " 'Premierministerin',\n",
       " 'Frankfurter',\n",
       " 'spricht',\n",
       " 'mit dem',\n",
       " 'Verfolgen',\n",
       " 'China',\n",
       " 'im Liveticker',\n",
       " 'stellt',\n",
       " 'großen',\n",
       " 'Frankfurt',\n",
       " 'Deutsche',\n",
       " 'Bild',\n",
       " 'lässt',\n",
       " 'lange',\n",
       " 'Euro',\n",
       " 'Wahl',\n",
       " 'bei der',\n",
       " 'Rennen',\n",
       " 'März',\n",
       " 'Dortmund',\n",
       " 'Champions League',\n",
       " 'Dirk Nowitzki',\n",
       " 'vergangenen',\n",
       " 'mit der',\n",
       " 'Briten',\n",
       " 'Regierung',\n",
       " 'besten',\n",
       " 'Formel',\n",
       " 'Interview',\n",
       " 'gewinnt',\n",
       " 'alte',\n",
       " 'Mittwoch',\n",
       " 'auf dem',\n",
       " 'April',\n",
       " 'sorgt',\n",
       " 'Angela',\n",
       " 'Augsburg',\n",
       " 'auf die',\n",
       " 'Opfer',\n",
       " 'Woche',\n",
       " 'Vereinigten',\n",
       " 'Geld',\n",
       " 'Bremen',\n",
       " 'Trumps',\n",
       " 'Staaten',\n",
       " 'auf der',\n",
       " 'NBA',\n",
       " 'nach dem',\n",
       " 'und die',\n",
       " 'Markus',\n",
       " 'Stuttgart',\n",
       " 'mit einem',\n",
       " '1000',\n",
       " 'Vettel',\n",
       " 'Loch',\n",
       " 'Millionen',\n",
       " '2019',\n",
       " 'Partei',\n",
       " 'hält',\n",
       " 'amerikanische',\n",
       " 'deutlich',\n",
       " 'Benjamin',\n",
       " 'in die',\n",
       " 'Anfang',\n",
       " 'Deutschen',\n",
       " 'Julian Assange',\n",
       " 'Vater',\n",
       " 'beendet',\n",
       " 'Platz',\n",
       " 'britischen',\n",
       " 'Sebastian',\n",
       " 'droht',\n",
       " 'Kritik',\n",
       " 'Robert',\n",
       " 'Druck',\n",
       " 'aus der',\n",
       " 'Tag',\n",
       " 'für den',\n",
       " 'Schalke',\n",
       " 'ist ein',\n",
       " 'Debatte',\n",
       " 'Lösung',\n",
       " 'Stadt',\n",
       " 'amerikanischen',\n",
       " '20',\n",
       " 'Mainz',\n",
       " 'Borussia',\n",
       " 'Gericht',\n",
       " 'Oktober',\n",
       " 'Bank',\n",
       " 'nächsten',\n",
       " 'Präsidenten',\n",
       " 'Karriere',\n",
       " 'Kampf',\n",
       " 'erfolgreich',\n",
       " 'frühere',\n",
       " 'in einer',\n",
       " 'läuft',\n",
       " 'Familie',\n",
       " 'Theresa May',\n",
       " 'verliert',\n",
       " 'trifft',\n",
       " 'Flughafen',\n",
       " 'Manchester',\n",
       " 'Botschaft',\n",
       " 'auf den',\n",
       " 'und der',\n",
       " 'alten',\n",
       " 'Köln',\n",
       " 'Unternehmen',\n",
       " 'Land',\n",
       " 'of',\n",
       " 'Hannover',\n",
       " 'Sudan',\n",
       " 'Probleme',\n",
       " 'Tor',\n",
       " 'in den',\n",
       " 'Boeing',\n",
       " 'liegen',\n",
       " 'führt',\n",
       " 'WikileaksGründer',\n",
       " 'Instagram',\n",
       " 'Thrones',\n",
       " 'Zukunft',\n",
       " 'zahlen',\n",
       " 'Pressekonferenz',\n",
       " 'Game of Thrones',\n",
       " 'Jahres',\n",
       " 'Verfolgen Sie',\n",
       " 'Game',\n",
       " 'aus dem',\n",
       " 'Game of',\n",
       " '21',\n",
       " 'Hauptstadt',\n",
       " 'Bundesliga im',\n",
       " 'Prozent',\n",
       " 'Bundesliga im Liveticker',\n",
       " 'Altmaier',\n",
       " 'Staatsanwalt',\n",
       " 'Gegner',\n",
       " 'Augusta',\n",
       " 'Woods',\n",
       " 'Parlament',\n",
       " 'Schwarzen',\n",
       " 'Star',\n",
       " 'von der',\n",
       " 'um die',\n",
       " 'Tiger',\n",
       " 'größte',\n",
       " 'Haft',\n",
       " 'Schüler',\n",
       " 'stehen',\n",
       " 'Bundestag',\n",
       " '2018',\n",
       " 'Gantz',\n",
       " 'in London',\n",
       " 'Mick',\n",
       " 'Geschichte',\n",
       " 'sich die',\n",
       " 'Posten',\n",
       " 'ist die',\n",
       " 'Migranten',\n",
       " 'Freitag',\n",
       " 'Ministerpräsident',\n",
       " 'Europawahl',\n",
       " 'Donnerstag',\n",
       " 'Forscher',\n",
       " 'BVB',\n",
       " 'Zahl',\n",
       " 'dem Weg',\n",
       " 'Netflix',\n",
       " 'Michael',\n",
       " 'Istanbul',\n",
       " 'Milliarden',\n",
       " 'mit einer',\n",
       " 'Opposition',\n",
       " 'Montag',\n",
       " 'Kanzlerin',\n",
       " 'Spiele',\n",
       " 'zweiten',\n",
       " 'Max',\n",
       " 'Grenze',\n",
       " 'Flugzeug',\n",
       " 'Regierungschefs',\n",
       " 'leben',\n",
       " 'Peter',\n",
       " 'verlassen',\n",
       " 'Martin',\n",
       " 'verhaftet',\n",
       " 'spielt',\n",
       " 'in Deutschland',\n",
       " 'mehr als',\n",
       " 'Gastbeitrag',\n",
       " '50',\n",
       " 'Forderungen',\n",
       " 'das Spiel',\n",
       " 'Wochen',\n",
       " 'Hamilton',\n",
       " 'Gladbach',\n",
       " 'Samstag',\n",
       " 'Fristverlängerung',\n",
       " 'Bericht',\n",
       " 'Lochs',\n",
       " 'Abgang',\n",
       " 'Scheuer',\n",
       " 'Tagen',\n",
       " 'schwer',\n",
       " 'Frauen',\n",
       " 'nahe',\n",
       " 'Leben',\n",
       " 'Haus',\n",
       " 'Studie',\n",
       " 'CDU',\n",
       " 'Street',\n",
       " 'Kunst',\n",
       " 'um den',\n",
       " 'und das',\n",
       " 'Grünen',\n",
       " 'Kim',\n",
       " 'heißt',\n",
       " 'Karriereende',\n",
       " 'Sonntag',\n",
       " 'Sieger',\n",
       " 'Sieg',\n",
       " 'gefunden',\n",
       " 'Verfolgen Sie das',\n",
       " 'Gefahr',\n",
       " 'Fußball',\n",
       " 'Blick',\n",
       " 'Russland',\n",
       " 'Frankreich',\n",
       " 'Benedikt',\n",
       " 'Paris',\n",
       " 'Premierministerin Theresa',\n",
       " 'Frage',\n",
       " 'die EU',\n",
       " 'über die',\n",
       " 'bekommen',\n",
       " 'erklärt',\n",
       " 'Innenminister',\n",
       " 'Schumacher',\n",
       " 'Nielsen',\n",
       " 'Grand',\n",
       " 'hilft',\n",
       " 'Chance',\n",
       " 'Führung',\n",
       " 'alt',\n",
       " 'Wall',\n",
       " 'Anschlag',\n",
       " 'diskutiert',\n",
       " 'BrexitAufschub',\n",
       " 'ist das',\n",
       " 'Reinhard',\n",
       " 'TVKritik',\n",
       " 'glücklich',\n",
       " 'Duell',\n",
       " 'Mitarbeiter',\n",
       " 'Straßen',\n",
       " 'offen',\n",
       " 'getötet',\n",
       " 'Serie',\n",
       " 'holt',\n",
       " 'Sicht',\n",
       " 'Event',\n",
       " 'Medien',\n",
       " 'Deutscher',\n",
       " 'Masters',\n",
       " 'über den',\n",
       " 'Tusk',\n",
       " 'Ausstellung',\n",
       " 'Fridays',\n",
       " 'Horizon',\n",
       " 'Spitze',\n",
       " 'Jahre alte',\n",
       " 'nicht nur',\n",
       " 'Future',\n",
       " 'City',\n",
       " 'ist der',\n",
       " 'vor allem',\n",
       " 'Papst',\n",
       " 'Commerzbank',\n",
       " 'Alexander',\n",
       " 'Die britische',\n",
       " 'ehemalige',\n",
       " 'Liverpool',\n",
       " '05',\n",
       " 'Verlängerung',\n",
       " 'Berliner',\n",
       " 'Autos',\n",
       " 'Soldaten',\n",
       " 'Netanjahus',\n",
       " 'Fälle',\n",
       " 'Intelligenz',\n",
       " 'bei einem',\n",
       " 'Position',\n",
       " 'bei einer',\n",
       " 'Polizisten',\n",
       " 'für das',\n",
       " 'Israels',\n",
       " 'Insel',\n",
       " 'politische',\n",
       " 'Sie das',\n",
       " 'Lissabon',\n",
       " 'vorerst',\n",
       " 'hat die',\n",
       " 'sucht',\n",
       " 'hebt',\n",
       " 'Benfica',\n",
       " 'gibt es',\n",
       " 'Ermittlungen',\n",
       " 'Unbekannte',\n",
       " 'Freiheit',\n",
       " 'Thomas',\n",
       " 'Ärger',\n",
       " 'Assistent',\n",
       " 'Uber',\n",
       " 'erstmals',\n",
       " 'schön',\n",
       " 'Hecking',\n",
       " 'Wirtschaft',\n",
       " 'verlässt',\n",
       " 'Eindruck',\n",
       " 'der Welt',\n",
       " 'Pole',\n",
       " 'Test',\n",
       " 'Deutschlands',\n",
       " 'Grindel',\n",
       " 'zeigen',\n",
       " 'Schauspielerin',\n",
       " 'Friedrich',\n",
       " 'sind die',\n",
       " 'Anne',\n",
       " 'Bottas',\n",
       " 'Donald Trump',\n",
       " 'Zentrum',\n",
       " 'bekommt',\n",
       " 'Zug',\n",
       " 'Dieter',\n",
       " 'Mainzer',\n",
       " 'Parlamentswahl',\n",
       " 'für einen',\n",
       " 'Duisburg',\n",
       " 'Schmidt',\n",
       " 'Mörder',\n",
       " 'Andreas',\n",
       " 'Entscheidung',\n",
       " 'beste',\n",
       " 'nennt',\n",
       " 'Die britische Premierministerin',\n",
       " 'Herausforderer',\n",
       " 'Londoner',\n",
       " 'Barcelona',\n",
       " 'versucht']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = list(features_sort.index)\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary={}\n",
    "\n",
    "for i in range(len(feature_list)):\n",
    "    dictionary[feature_list[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over 'politik' buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_buzzword = []\n",
    "\n",
    "for index, row in faz_pol.iterrows():\n",
    "    new_line = np.zeros(400)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    pol_buzzword.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol = pd.DataFrame(pol_buzzword, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol['goal_val'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over 'sport' buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_buzzword = []\n",
    "\n",
    "for index, row in faz_sport.iterrows():\n",
    "    new_line = np.zeros(400)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    sport_buzzword.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport = pd.DataFrame(sport_buzzword, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport['goal_val'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over 'wirtschaft' buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_buzzword = []\n",
    "\n",
    "for index, row in faz_eco.iterrows():\n",
    "    new_line = np.zeros(400)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    eco_buzzword.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eco = pd.DataFrame(eco_buzzword, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eco['goal_val'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over remaining buzzwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_buzzword = []\n",
    "\n",
    "for index, row in faz_rem.iterrows():\n",
    "    new_line = np.zeros(400)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    rem_buzzword.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem = pd.DataFrame(rem_buzzword, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem['goal_val'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [df_pol, df_eco, df_sport, df_rem]\n",
    "train_data = pd.concat(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**saving the train data frames to a .csv file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathname: ../data_frames/train_data\n"
     ]
    }
   ],
   "source": [
    "name = 'train_data'\n",
    "\n",
    "path = \"../data_frames/\" + name\n",
    "print(\"Pathname:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAME FOR TEST DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_tables(category):\n",
    "    raw_article = []\n",
    "    if category is 'aktuell':\n",
    "        path = f\"../data/aktuell/\"\n",
    "    else:\n",
    "        path = f\"../data/{category}/\"\n",
    "        \n",
    "    all_files = glob.glob(path + '*.csv')\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        raw_article.append(df)\n",
    "    faz_article = pd.concat(raw_article, axis=0, ignore_index=True)\n",
    "    faz_article['label'] = category\n",
    "\n",
    "    return faz_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fram = []\n",
    "\n",
    "for key, value in category.items():\n",
    "    raw_test = build_test_tables(value)\n",
    "    fram.append(raw_test)\n",
    "    faz_test = pd.concat(fram, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_test = faz_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_pol_t = faz_test[faz_test.label == 'politik']\n",
    "faz_sport_t = faz_test[faz_test.label == 'sport']\n",
    "faz_eco_t = faz_test[faz_test.label == 'wirtschaft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_test_2 = faz_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_test_2 = faz_test_2[faz_test_2.label != 'politik']\n",
    "faz_test_2 = faz_test_2[faz_test_2.label != 'sport']\n",
    "faz_test_2 = faz_test_2[faz_test_2.label != 'wirtschaft']\n",
    "faz_rem_t = faz_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pol_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_buzzword_t = []\n",
    "\n",
    "for index, row in faz_pol_t.iterrows():\n",
    "    new_line = np.zeros(400)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    pol_buzzword_t.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_t = pd.DataFrame(pol_buzzword_t, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_t['goal_val'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sport_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_buzzword_t = []\n",
    "\n",
    "for index, row in faz_sport_t.iterrows():\n",
    "    new_line = np.zeros(400)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    sport_buzzword_t.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport_t = pd.DataFrame(sport_buzzword_t, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport_t['goal_val'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eco_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_buzzword_t = []\n",
    "\n",
    "for index, row in faz_eco_t.iterrows():\n",
    "    new_line = np.zeros(400)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    eco_buzzword_t.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eco_t = pd.DataFrame(eco_buzzword_t, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eco_t['goal_val'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rem_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_buzzword_t = []\n",
    "\n",
    "for index, row in faz_rem_t.iterrows():\n",
    "    new_line = np.zeros(400)\n",
    "    words = list(row['detailed'].split(' '))\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            new_line[dictionary[word]] += 1\n",
    "    rem_buzzword_t.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_t = pd.DataFrame(rem_buzzword_t, columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_t['goal_val'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tables = [df_pol_t, df_sport_t, df_eco_t, df_rem_t]\n",
    "top_test_data = pd.concat(test_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**saving the data frames to a .csv file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathname: ../data_frames/test_data\n"
     ]
    }
   ],
   "source": [
    "name = 'test_data'\n",
    "\n",
    "path = \"../data_frames/\" + name\n",
    "print(\"Pathname:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_test_data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
